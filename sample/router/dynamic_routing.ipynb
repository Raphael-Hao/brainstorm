{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Routing with Default Dispatcher and 2-D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0282,  0.8077, -0.1290, -0.0281, -0.2477, -1.0221,  0.3454, -0.3232,\n",
      "          0.2726,  0.3481],\n",
      "        [ 0.2142, -0.4677, -0.0294, -1.2462, -0.0145,  0.1233, -0.1467, -0.0757,\n",
      "         -0.1168, -0.4898],\n",
      "        [-0.5658,  0.2220, -0.7049,  0.0997, -0.4098, -0.1703, -0.1509,  0.0133,\n",
      "          0.6791, -0.2452]], grad_fn=<AliasBackward0>)\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.2465, -1.7525, -0.9535, -0.8834, -0.8782, -0.1326, -1.4295, -0.1853,\n",
      "         -0.1577,  0.3481, -0.8457, -0.0894,  1.0547,  1.5808, -0.0763, -0.9335,\n",
      "         -1.6403,  0.9497,  0.8951, -0.1301],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5136,  0.8039,  0.1637,  0.6073, -0.3397, -0.5024,  0.4065,  0.7879,\n",
      "          0.0852,  0.3462,  0.6087,  0.4642,  0.1708, -0.1903,  0.0958,  0.2067,\n",
      "          0.0284, -0.0652,  0.3071,  0.4368]], grad_fn=<AliasBackward0>)\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0282,  0.8077, -0.1290, -0.0281, -0.2477, -1.0221,  0.3454, -0.3232,\n",
      "          0.2726,  0.3481],\n",
      "        [ 0.2142, -0.4677, -0.0294, -1.2462, -0.0145,  0.1233, -0.1467, -0.0757,\n",
      "         -0.1168, -0.4898],\n",
      "        [-0.5658,  0.2220, -0.7049,  0.0997, -0.4098, -0.1703, -0.1509,  0.0133,\n",
      "          0.6791, -0.2452]], device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.2465, -1.7525, -0.9535, -0.8834, -0.8782, -0.1326, -1.4295, -0.1853,\n",
      "         -0.1577,  0.3481, -0.8457, -0.0894,  1.0547,  1.5808, -0.0763, -0.9335,\n",
      "         -1.6403,  0.9497,  0.8951, -0.1301],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5136,  0.8039,  0.1637,  0.6073, -0.3397, -0.5024,  0.4065,  0.7879,\n",
      "          0.0852,  0.3462,  0.6087,  0.4642,  0.1708, -0.1903,  0.0958,  0.2067,\n",
      "          0.0284, -0.0652,  0.3071,  0.4368]], device='cuda:0',\n",
      "       grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from brt.router import ScatterRouter, GatherRouter\n",
    "class DynamicRouting(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.route_func = nn.Sequential(nn.Linear(10, 2), nn.ReLU())\n",
    "        self.scatter_router_0 = ScatterRouter(\n",
    "            protocol_type=\"threshold\",\n",
    "            fabric_type=\"dispatch\",\n",
    "        )\n",
    "        self.scatter_router_1 = ScatterRouter(\n",
    "            protocol_type=\"threshold\",\n",
    "            fabric_type=\"dispatch\",\n",
    "        )\n",
    "        self.expert1 = nn.Linear(10, 10)  # keep\n",
    "        self.expert2 = nn.Linear(10, 20)  # upsample\n",
    "        self.expert3 = nn.Linear(10, 10)\n",
    "        self.expert4 = nn.Linear(10, 20)\n",
    "        self.gather_router_0 = GatherRouter(fabric_type=\"combine\")\n",
    "        self.gather_router_1 = GatherRouter(fabric_type=\"combine\")\n",
    "    def forward(self, x, y):\n",
    "        x_gates = self.route_func(x)\n",
    "        y_gates = self.route_func(y)\n",
    "        route_results_x = self.scatter_router_0(x, x_gates)\n",
    "        route_results_y = self.scatter_router_1(y, y_gates)\n",
    "        x_0 = self.expert1(route_results_x[0])\n",
    "        x_1 = self.expert2(route_results_x[1])\n",
    "        y_0 = self.expert3(route_results_y[0])\n",
    "        y_1 = self.expert4(route_results_y[1])\n",
    "        x = self.gather_router_0([x_0, y_0])\n",
    "        y = self.gather_router_1([x_1, y_1])\n",
    "        return x, y\n",
    "dy_model = DynamicRouting()\n",
    "for i in range(1):\n",
    "    in_x = torch.randn((4, 10))\n",
    "    in_y = torch.randn((4, 10))\n",
    "    dy_model.cpu()\n",
    "    cpu_x, cpu_y = dy_model(in_x.cpu(), in_y.cpu())\n",
    "    print(cpu_x)\n",
    "    print(cpu_y)\n",
    "    dy_model.cuda()\n",
    "    cuda_x, cuda_y = dy_model(in_x.cuda(), in_y.cuda())\n",
    "    print(cuda_x)\n",
    "    print(cuda_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Routing with Residual Router and 2-D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.5302e-01,  2.9965e-01,  5.8934e-01,  8.7531e-01, -1.5401e-03,\n",
      "         -5.6871e-01, -3.6920e-01, -1.4634e+00, -1.8272e+00, -7.1656e-01],\n",
      "        [-2.0284e-01, -8.0398e-01, -7.8178e-01,  2.0861e-01,  1.2111e-03,\n",
      "          2.2141e-01,  9.5521e-01, -7.1936e-01, -8.9217e-01, -6.1342e-01],\n",
      "        [ 3.6026e-01, -5.1783e-01,  6.6238e-02, -1.1183e-01, -1.2101e+00,\n",
      "         -1.1991e+00,  1.2025e-01, -8.2009e-01,  5.7306e-02, -6.1690e-01]],\n",
      "       device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4210,  0.3431,  0.5573, -0.1178, -0.0333, -0.8537, -0.2588,  0.7704,\n",
      "         -0.9808,  0.1526, -0.8461, -0.1137, -0.5458,  0.0428, -0.9736,  0.8381,\n",
      "          1.0214,  0.0178,  0.0434,  1.0804]], device='cuda:0',\n",
      "       grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from brt.router import ScatterRouter, GatherRouter\n",
    "\n",
    "\n",
    "class DynamicRouting(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.route_func = nn.Sequential(nn.Linear(10, 2), nn.ReLU())\n",
    "        self.scatter_router_0 = ScatterRouter(\n",
    "            protocol_type=\"threshold\",\n",
    "            fabric_type=\"dispatch\",\n",
    "        )\n",
    "        self.scatter_router_1 = ScatterRouter(\n",
    "            protocol_type=\"threshold\",\n",
    "            fabric_type=\"dispatch\",\n",
    "        )\n",
    "        self.expert1 = nn.Linear(10, 10)\n",
    "        self.expert2 = nn.Linear(10, 20)\n",
    "        self.expert3 = nn.Linear(10, 10)\n",
    "        self.expert4 = nn.Linear(10, 20)\n",
    "        self.gather_router_0 = GatherRouter(fabric_type=\"combine\")\n",
    "        self.gather_router_1 = GatherRouter(fabric_type=\"combine\")\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x_gates = self.route_func(x)\n",
    "        y_gates = self.route_func(y)\n",
    "        route_results_x = self.scatter_router_0(x, x_gates)\n",
    "        route_results_y = self.scatter_router_1(y, y_gates)\n",
    "        x_0 = self.expert1(route_results_x[0])\n",
    "        x_1 = self.expert2(route_results_x[1])\n",
    "        y_0 = self.expert3(route_results_y[0])\n",
    "        y_1 = self.expert4(route_results_y[1])\n",
    "        x = self.gather_router_0([x_0, y_0])\n",
    "        y = self.gather_router_1([x_1, y_1])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "dy_model = DynamicRouting()\n",
    "dy_model.cuda()\n",
    "\n",
    "for i in range(1):\n",
    "    x = torch.randn((3, 10)).cuda()\n",
    "    y = torch.randn((3, 10)).cuda()\n",
    "\n",
    "    x, y = dy_model(x, y)\n",
    "\n",
    "    print(x)\n",
    "    print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Routing with Residual Router and 2-D tensor while routing gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from brt.router import ScatterRouter, GatherRouter\n",
    "\n",
    "\n",
    "class DynamicRouting(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.route_func = nn.Sequential(nn.Linear(10, 2), nn.ReLU())\n",
    "        self.scatter_router_0 = ScatterRouter(\n",
    "            dispatch_score=True,\n",
    "            protocol_type=\"threshold\",\n",
    "            fabric_type=\"dispatch\",\n",
    "        )\n",
    "        self.scatter_router_1 = ScatterRouter(\n",
    "            protocol_type=\"threshold\",\n",
    "            fabric_type=\"dispatch\",\n",
    "        )\n",
    "        self.expert1 = nn.Linear(10, 10)\n",
    "        self.expert2 = nn.Linear(10, 20)\n",
    "        self.expert3 = nn.Linear(10, 10)\n",
    "        self.expert4 = nn.Linear(10, 20)\n",
    "        self.gather_router_0 = GatherRouter(fabric_type=\"combine\")\n",
    "        self.gather_router_1 = GatherRouter(fabric_type=\"combine\")\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x_gates = self.route_func(x)\n",
    "        y_gates = self.route_func(y)\n",
    "        route_results_x, route_gates_x = self.scatter_router_0(x, x_gates)\n",
    "        route_results_y = self.scatter_router_1(y, y_gates)\n",
    "        x_0 = self.expert1(route_results_x[0])\n",
    "        x_0 = route_gates_x[0] * x_0\n",
    "        x_1 = self.expert2(route_results_x[1])\n",
    "        x_1 = route_gates_x[1] * x_1\n",
    "        y_0 = self.expert3(route_results_y[0])\n",
    "        y_1 = self.expert4(route_results_y[1])\n",
    "        x = self.gather_router_0([x_0, y_0])\n",
    "        y = self.gather_router_1([x_1, y_1])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "dy_model = DynamicRouting()\n",
    "dy_model.cuda()\n",
    "for i in range(10):\n",
    "    x = torch.randn((3, 10)).cuda()\n",
    "    y = torch.randn((3, 10)).cuda()\n",
    "\n",
    "    x, y = dy_model(x, y)\n",
    "\n",
    "    # print(x.shape)\n",
    "    # print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Routing with Residual Router and 4-D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([3, 8, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([0, 8, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([3, 8, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([0, 8, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([0, 8, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([0, 8, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([0, 8, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([0, 8, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([3, 8, 2, 2])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "torch.Size([3, 8, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from brt.router import ScatterRouter, GatherRouter\n",
    "\n",
    "\n",
    "route_func = (\n",
    "    lambda x: nn.Sequential(\n",
    "        nn.Conv2d(4, 2, 1),\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Conv2d(2, 2, 1),\n",
    "    )\n",
    "    .cuda()(x)\n",
    "    .view(-1, 2)\n",
    ")  # [bs x dst_num x 1 x 1] keep up down -> keep down\n",
    "\n",
    "\n",
    "class DynamicRouting(nn.Module):\n",
    "    def __init__(self, dst_num):\n",
    "        super().__init__()\n",
    "        self.route_func = nn.Sequential(\n",
    "            nn.Conv2d(4, 2, 1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Conv2d(2, 2, 1),\n",
    "        )\n",
    "        self.scatter_router_0 = ScatterRouter(\n",
    "            dispatch_score=True,\n",
    "            protocol_type=\"threshold\",\n",
    "            fabric_type=\"dispatch\",\n",
    "        )\n",
    "        self.scatter_router_1 = ScatterRouter(\n",
    "            protocol_type=\"threshold\",\n",
    "            fabric_type=\"dispatch\",\n",
    "        )\n",
    "        self.expert1 = nn.Conv2d(4, 4, 1)\n",
    "        self.expert2 = nn.Conv2d(4, 8, 1)\n",
    "        self.expert3 = nn.Conv2d(4, 4, 1)\n",
    "        self.expert4 = nn.Conv2d(4, 8, 1)\n",
    "        self.gather_router_0 = GatherRouter(fabric_type=\"combine\")\n",
    "        self.gather_router_1 = GatherRouter(fabric_type=\"combine\")\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        gates_x = self.route_func(x).view(-1, 2)\n",
    "        gates_y = self.route_func(y).view(-1, 2)\n",
    "        route_results_x, _ = self.scatter_router_0(x, gates_x)\n",
    "        route_results_y = self.scatter_router_1(y, gates_y)\n",
    "        x_0 = self.expert1(route_results_x[0])\n",
    "        x_1 = self.expert2(route_results_x[1])\n",
    "        y_0 = self.expert3(route_results_y[0])\n",
    "        y_1 = self.expert4(route_results_y[1])\n",
    "        x = self.gather_router_0([x_0, y_0])\n",
    "        y = self.gather_router_1([x_1, y_1])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "dy_model = DynamicRouting(2)\n",
    "dy_model.cuda()\n",
    "for i in range(10):\n",
    "    x = torch.randn((3, 4, 2, 2)).cuda()\n",
    "    y = torch.randn((3, 4, 2, 2)).cuda()\n",
    "    x, y = dy_model(x, y)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('begin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c13eb689fd642ac0827e1e3dddd38907462b9b7b4d2186008cc2bf0647b540d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
