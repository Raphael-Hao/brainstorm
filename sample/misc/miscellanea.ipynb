{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_local_indices elapsed time: 0.205\n",
      "route_with_local_indices elapsed time: 0.347\n",
      "route_back_with_local_indices elapsed time: 0.189\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from brt.routers.app import RandHomoFusedScatterRouter\n",
    "from brt.routers.inference import HomoFusedGatherRouter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class FusedMoE(nn.Module):\n",
    "    def __init__(self, expert_num):\n",
    "        super().__init__()\n",
    "        self.scatter_router = RandHomoFusedScatterRouter(\n",
    "            dst_num=expert_num,\n",
    "            supported_capacities=[\n",
    "                2,\n",
    "                4,\n",
    "                8,\n",
    "                16,\n",
    "                32,\n",
    "                64,\n",
    "                128,\n",
    "                256,\n",
    "                512,\n",
    "                1024,\n",
    "                2048,\n",
    "                4096,\n",
    "                8192,\n",
    "            ],\n",
    "        )\n",
    "        self.gather_router = HomoFusedGatherRouter(dst_num=expert_num)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        route_results = self.scatter_router(inputs)\n",
    "        # print(route_results)\n",
    "        route_results = self.gather_router(route_results)\n",
    "        return route_results\n",
    "\n",
    "\n",
    "fused_moe = FusedMoE(expert_num=8).cuda()\n",
    "\n",
    "input_tensor = torch.rand((1024, 64)).cuda()\n",
    "# print(input_tensor)\n",
    "output_tensor = fused_moe(input_tensor)\n",
    "# print(output_tensor)\n",
    "print(torch.allclose(output_tensor, input_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "        self.conv = nn.Conv2d(3, 3, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "simple_net =SimpleNet()\n",
    "simple_net.eval()\n",
    "in_data = torch.randn(1,3,10,10)\n",
    "with torch.inference_mode():\n",
    "    origin_out_data = simple_net(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0\n",
      "Reserved: 0\n",
      "Allocated: 0\n",
      "Reserved: 0\n",
      "Allocated: 0\n",
      "Reserved: 0\n"
     ]
    }
   ],
   "source": [
    "from brt.runtime.preload import load_module, pin_memory, unload_module\n",
    "\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()}\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved()}\")\n",
    "\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()}\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved()}\")\n",
    "\n",
    "pinned_simple_net = pin_memory(simple_net)\n",
    "pinned_simple_net.eval()\n",
    "with torch.inference_mode():\n",
    "    pinned_out_data = pinned_simple_net(in_data)\n",
    "\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()}\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 2048\n",
      "Reserved: 2097152\n"
     ]
    }
   ],
   "source": [
    "cuda_simple_net = load_module(pinned_simple_net)\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()}\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 3584\n",
      "Reserved: 2097152\n",
      "Allocated: 4608\n",
      "Reserved: 2097152\n",
      "Allocated: 3072\n",
      "Reserved: 2097152\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cuda_simple_net.eval()\n",
    "cuda_in_data = in_data.cuda()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()}\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved()}\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    cuda_out_data = cuda_simple_net(cuda_in_data)\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()}\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved()}\")\n",
    "\n",
    "cuda_in_data=None\n",
    "# cuda_out_data = None\n",
    "\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()}\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 1024\n",
      "Reserved: 2097152\n",
      "Allocated: 1024\n",
      "Reserved: 2097152\n"
     ]
    }
   ],
   "source": [
    "unload_simple_net = unload_module(cuda_simple_net)\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()}\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved()}\")\n",
    "\n",
    "unload_simple_net.eval()\n",
    "with torch.inference_mode():\n",
    "    unload_out_data = unload_simple_net(in_data)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated()}\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9538, 0.7407, 0.8528],\n",
      "        [0.2403, 0.2152, 0.0866]])\n",
      "tensor([[0.9538, 0.7407, 0.8528],\n",
      "        [0.2403, 0.2152, 0.0866]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def _get_input(inputs, path_id):\n",
    "    if isinstance(inputs, (tuple, list)):\n",
    "        if len(inputs) > path_id and isinstance(inputs[path_id], torch.Tensor):\n",
    "            return inputs[path_id]\n",
    "        else:\n",
    "            return _get_input(inputs[0], path_id)\n",
    "\n",
    "\n",
    "a = [torch.rand((2, 3)) for i in range(10)]\n",
    "\n",
    "print(a[3])\n",
    "\n",
    "b = _get_input(a, 3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4914c35dbc1a262acb2241fbfc193aaeb9362d455da2cebdd4b0a1d658dbfd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
