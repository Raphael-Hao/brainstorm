{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.]])\n",
      "graph(%self : __torch__.___torch_mangle_256.MoE,\n",
      "      %x.1 : Tensor):\n",
      "  %10 : int = prim::Constant[value=0]() # /tmp/ipykernel_1526473/1513214202.py:18:41\n",
      "  %15 : int = prim::Constant[value=1]() # /tmp/ipykernel_1526473/1513214202.py:19:41\n",
      "  %scatter_router : __torch__.brt.router.scatter.RandomScatterRouter = prim::GetAttr[name=\"scatter_router\"](%self)\n",
      "  %4 : (Tensor[], Tensor[], int) = prim::CallMethod[name=\"forward\"](%scatter_router, %x.1) # /tmp/ipykernel_1526473/1513214202.py:17:43\n",
      "  %route_results.1 : Tensor[], %route_tags.1 : Tensor[], %loads.1 : int = prim::TupleUnpack(%4)\n",
      "  %expert1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"expert1\"](%self)\n",
      "  %11 : Tensor = aten::__getitem__(%route_results.1, %10) # /tmp/ipykernel_1526473/1513214202.py:18:27\n",
      "  %x_0.1 : Tensor = prim::CallMethod[name=\"forward\"](%expert1, %11) # /tmp/ipykernel_1526473/1513214202.py:18:14\n",
      "  %expert2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"expert2\"](%self)\n",
      "  %16 : Tensor = aten::__getitem__(%route_results.1, %15) # /tmp/ipykernel_1526473/1513214202.py:19:27\n",
      "  %x_1.1 : Tensor = prim::CallMethod[name=\"forward\"](%expert2, %16) # /tmp/ipykernel_1526473/1513214202.py:19:14\n",
      "  %gather_router : __torch__.brt.router.gather.GatherRouter = prim::GetAttr[name=\"gather_router\"](%self)\n",
      "  %21 : Tensor[] = prim::ListConstruct(%x_0.1, %x_1.1)\n",
      "  %x.5 : Tensor = prim::CallMethod[name=\"forward\"](%gather_router, %21, %route_tags.1, %loads.1) # /tmp/ipykernel_1526473/1513214202.py:20:12\n",
      "  return (%x.5)\n",
      "\n",
      "graph(%x.1 : Float(2, 10, strides=[10, 1], requires_grad=0, device=cpu),\n",
      "      %moe.expert1.bias : Float(10, strides=[1], requires_grad=0, device=cpu),\n",
      "      %moe.expert2.bias : Float(10, strides=[1], requires_grad=0, device=cpu),\n",
      "      %21 : Float(10, 10, strides=[1, 10], requires_grad=0, device=cpu),\n",
      "      %22 : Float(10, 10, strides=[1, 10], requires_grad=0, device=cpu)):\n",
      "  %5 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %6 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %self.moe.scatter_router.route_num : Long(device=cpu) = onnx::Constant[value={2}]()\n",
      "  %8 : Tensor[], %9 : Tensor[], %10 : Long(device=cpu) = brt::scatter_route(%x.1, %self.moe.scatter_router.route_num) # /home/whcui/brainstorm_project/brainstorm/python/brt/router/scatter.py:83:15\n",
      "  %11 : Tensor = onnx::SequenceAt(%8, %6) # /tmp/ipykernel_1526473/1513214202.py:18:27\n",
      "  %13 : Tensor = onnx::MatMul(%11, %21) # /state/partition/whcui/tools/pyenv/versions/miniconda3-3.8-4.10.3/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:15\n",
      "  %x_0 : FloatTensor = onnx::Add(%moe.expert1.bias, %13) # /state/partition/whcui/tools/pyenv/versions/miniconda3-3.8-4.10.3/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:15\n",
      "  %15 : Tensor = onnx::SequenceAt(%8, %5) # /tmp/ipykernel_1526473/1513214202.py:19:27\n",
      "  %17 : Tensor = onnx::MatMul(%15, %22) # /state/partition/whcui/tools/pyenv/versions/miniconda3-3.8-4.10.3/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:15\n",
      "  %x_1 : FloatTensor = onnx::Add(%moe.expert2.bias, %17) # /state/partition/whcui/tools/pyenv/versions/miniconda3-3.8-4.10.3/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:15\n",
      "  %19 : FloatTensor(device=cpu)[] = onnx::SequenceConstruct(%x_0, %x_1)\n",
      "  %x : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = brt::gather_route(%19, %9, %10, %self.moe.scatter_router.route_num) # /home/whcui/brainstorm_project/brainstorm/python/brt/router/gather.py:57:15\n",
      "  return (%x)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::gather_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::gather_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::gather_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import brt.frontend.symbolic\n",
    "import brt.frontend.nn as nn\n",
    "from brt.routers.app import RandScatterRouter, RandGatherRouter\n",
    "from brt.frontend import symbolize\n",
    "\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scatter_router = RandScatterRouter(route_num=2)\n",
    "        self.expert1 = nn.Linear(10, 10)\n",
    "        self.expert2 = nn.Linear(10, 10)\n",
    "        self.gather_router = RandGatherRouter(route_num=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        route_results, route_tags, loads = self.scatter_router(x)\n",
    "        x_0 = self.expert1(route_results[0])\n",
    "        x_1 = self.expert2(route_results[1])\n",
    "        x = self.gather_router([x_0, x_1], route_tags, loads)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ThorMoE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.moe = MoE()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.moe(x)\n",
    "\n",
    "\n",
    "thor_moe = ThorMoE()\n",
    "thor_moe.eval()\n",
    "x = torch.arange(0, 20, dtype=torch.float32).view(2, 10)\n",
    "print(x)\n",
    "y = thor_moe(x)\n",
    "\n",
    "script_moe_model = torch.jit.script(symbolize(thor_moe))\n",
    "print(script_moe_model.moe.graph)\n",
    "\n",
    "torch.onnx.export(\n",
    "    script_moe_model,\n",
    "    x,\n",
    "    \"moe.onnx\",\n",
    "    verbose=True,\n",
    "    custom_opsets={\"brt\": 2},\n",
    "    opset_version=11,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]), tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]), tensor([1, 1])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of brt::scatter_route type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    }
   ],
   "source": [
    "from brt.runtime import find_lib_path\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "libpath = find_lib_path(\"libbrt_torchscript.so\")\n",
    "torch.ops.load_library(find_lib_path(\"libbrt_torchscript.so\")[0])\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, y, z):\n",
    "        super().__init__()\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "    def forward(self, x) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        (\n",
    "            route_results,\n",
    "            route_indices,\n",
    "            reverse_shape,\n",
    "        ) = torch.ops.brt.symbolic_scatter_route(x, self.y, self.z)\n",
    "        results = torch.stack(route_results, dim=0)\n",
    "        indices = torch.stack(route_indices, dim=0)\n",
    "        return results, indices, reverse_shape\n",
    "\n",
    "\n",
    "model = Model(0, 2)\n",
    "script_model = torch.jit.script(model)\n",
    "\n",
    "x = torch.Tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "\n",
    "torch.onnx.export(\n",
    "    script_model, x, \"scatter_route.onnx\", custom_opsets={\"brt\": 2}, opset_version=14\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4914c35dbc1a262acb2241fbfc193aaeb9362d455da2cebdd4b0a1d658dbfd5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
