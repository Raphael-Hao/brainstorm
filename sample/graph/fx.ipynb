{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:brainstorm.routers:residual_path is not specified for Threshold route method, use default residual_path=-1\n",
      "[2022-07-08 00:52:52] WARNING (brainstorm.routers/MainThread) residual_path is not specified for Threshold route method, use default residual_path=-1\n",
      "tensor([[ -0.4084,  -3.6441,   1.4626,   1.5102,  -0.4632,  -4.9812,  -3.4973,\n",
      "           7.3618,  -3.3022,  -5.5773],\n",
      "        [ 13.0121,  -5.2027,  12.9716,   2.6283,  11.0787,   1.8211,  -5.1149,\n",
      "          -0.7463,   3.1213,  -6.2672],\n",
      "        [ 21.5346,  -8.4781,  23.2726,   4.0588,  16.2145,   0.3744,  -8.7244,\n",
      "           0.7261,   7.0585, -12.7260]], grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from brt.common import log\n",
    "from brt.routers.app import RandScatterRouter\n",
    "from brt.routers import GatherRouter\n",
    "\n",
    "\n",
    "log.set_level(\"frontend\", \"INFO\")\n",
    "log.set_level(\"backend\", \"INFO\")\n",
    "log.set_level(\"ir\", \"INFO\")\n",
    "\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scatter_router = RandScatterRouter(path_num=2)\n",
    "        self.expert1 = nn.Linear(10, 10)\n",
    "        self.expert2 = nn.Linear(10, 10)\n",
    "        self.gather_router = GatherRouter(path_num=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        route_results = self.scatter_router(x)\n",
    "        x_0 = self.expert1(route_results[0])\n",
    "        x_1 = self.expert2(route_results[1])\n",
    "        x = self.gather_router([x_0, x_1])\n",
    "        return x\n",
    "\n",
    "\n",
    "class MoEModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.moe = MoE()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.moe(x)\n",
    "\n",
    "\n",
    "moe_model = MoEModel()\n",
    "indata = torch.arange(0, 30, dtype=torch.float32).view(3, 10)\n",
    "outdata = moe_model(indata)\n",
    "print(outdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brt.routers.app.rand\n"
     ]
    }
   ],
   "source": [
    "print(RandScatterRouter.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [#users=2] = placeholder[target=x]\n",
      "    %rand_gate : [#users=2] = call_function[target=brt.routers.app.rand.rand_gate](args = (%x, 2), kwargs = {})\n",
      "    %moe_scatter_router_scatter_router_protocol : [#users=1] = call_module[target=moe.scatter_router.scatter_router.protocol](args = (%rand_gate,), kwargs = {})\n",
      "    %moe_scatter_router_scatter_router_fabric : [#users=2] = call_module[target=moe.scatter_router.scatter_router.fabric](args = (%x, %moe_scatter_router_scatter_router_protocol, %rand_gate), kwargs = {})\n",
      "    %getitem : [#users=1] = call_function[target=operator.getitem](args = (%moe_scatter_router_scatter_router_fabric, 0), kwargs = {})\n",
      "    %moe_expert1 : [#users=1] = call_module[target=moe.expert1](args = (%getitem,), kwargs = {})\n",
      "    %getitem_1 : [#users=1] = call_function[target=operator.getitem](args = (%moe_scatter_router_scatter_router_fabric, 1), kwargs = {})\n",
      "    %moe_expert2 : [#users=1] = call_module[target=moe.expert2](args = (%getitem_1,), kwargs = {})\n",
      "    %moe_gather_router_fabric : [#users=1] = call_module[target=moe.gather_router.fabric](args = ([%moe_expert1, %moe_expert2],), kwargs = {})\n",
      "    return moe_gather_router_fabric\n",
      "\n",
      "torch.fx._symbolic_trace.wrap(\"brt_routers_app_rand_rand_gate\")\n",
      "\n",
      "def forward(self, x):\n",
      "    rand_gate = brt_routers_app_rand_rand_gate(x, 2)\n",
      "    moe_scatter_router_scatter_router_protocol = self.moe.scatter_router.scatter_router.protocol(rand_gate)\n",
      "    moe_scatter_router_scatter_router_fabric = self.moe.scatter_router.scatter_router.fabric(x, moe_scatter_router_scatter_router_protocol, rand_gate);  x = moe_scatter_router_scatter_router_protocol = rand_gate = None\n",
      "    getitem = moe_scatter_router_scatter_router_fabric[0]\n",
      "    moe_expert1 = self.moe.expert1(getitem);  getitem = None\n",
      "    getitem_1 = moe_scatter_router_scatter_router_fabric[1];  moe_scatter_router_scatter_router_fabric = None\n",
      "    moe_expert2 = self.moe.expert2(getitem_1);  getitem_1 = None\n",
      "    moe_gather_router_fabric = self.moe.gather_router.fabric([moe_expert1, moe_expert2]);  moe_expert1 = moe_expert2 = None\n",
      "    return moe_gather_router_fabric\n",
      "    \n",
      "tensor([[  4.4896,  -1.9274,   2.6705,   1.1979,   5.9428,   3.2678,  -1.5055,\n",
      "          -2.2188,  -0.8158,   0.1915],\n",
      "        [ 13.0121,  -5.2027,  12.9716,   2.6283,  11.0787,   1.8211,  -5.1149,\n",
      "          -0.7463,   3.1213,  -6.2672],\n",
      "        [ 13.0087, -12.2318,   7.8797,  15.3979,  -5.6275, -31.5762, -18.3005,\n",
      "          19.6282,  -7.7325, -22.8124]], grad_fn=<AliasBackward0>)\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': OrderedDict(), 'path_num': 2, 'start_event': <torch.cuda.Event uninitialized>, 'end_event': <torch.cuda.Event uninitialized>, 'route_logics': ['1d'], 'transforms': [False], 'indices_gen_opt': True}\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': OrderedDict(), 'path_num': 2, 'start_event': <torch.cuda.Event uninitialized>, 'end_event': <torch.cuda.Event uninitialized>, 'sparse': False, 'reduction': 'add'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition/whcui/tools/pyenv/versions/miniconda3-3.8-4.10.3/lib/python3.8/site-packages/torch/fx/graph_module.py:468: UserWarning: Was not able to save the following children modules as reprs -saved as pickled files instead: ['moe']\n",
      "  warnings.warn(\"Was not able to save the following children modules as reprs -\"\n"
     ]
    }
   ],
   "source": [
    "from brt.transform.tracer import BRTTRacer\n",
    "from torch.fx.graph_module import GraphModule\n",
    "from brt.common import BRT_CACHE_PATH\n",
    "tracer = BRTTRacer()\n",
    "graph = tracer.trace(moe_model)\n",
    "name = moe_model.__class__.__name__ if isinstance(moe_model, torch.nn.Module) else moe_model.__name__\n",
    "graph_module= GraphModule(tracer.root, graph, name)\n",
    "print(graph_module.graph)\n",
    "print(graph_module.code)\n",
    "outdata = graph_module(indata)\n",
    "print(outdata)\n",
    "graph_module.to_folder(BRT_CACHE_PATH/\"transformed_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4914c35dbc1a262acb2241fbfc193aaeb9362d455da2cebdd4b0a1d658dbfd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
