{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TraceError",
     "evalue": "symbolically traced variables cannot be used as inputs to control flow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraceError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/whcui/brainstorm_project/brainstorm/sample/graph/for_loop.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22413130302d3031227d/home/whcui/brainstorm_project/brainstorm/sample/graph/for_loop.ipynb#ch0000000vscode-remote?line=13'>14</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m xs\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22413130302d3031227d/home/whcui/brainstorm_project/brainstorm/sample/graph/for_loop.ipynb#ch0000000vscode-remote?line=16'>17</a>\u001b[0m for_loop_model \u001b[39m=\u001b[39m ForLoop()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22413130302d3031227d/home/whcui/brainstorm_project/brainstorm/sample/graph/for_loop.ipynb#ch0000000vscode-remote?line=17'>18</a>\u001b[0m s_for_loop_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfx\u001b[39m.\u001b[39;49msymbolic_trace(for_loop_model)\n",
      "File \u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-3.8-4.10.3/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:878\u001b[0m, in \u001b[0;36msymbolic_trace\u001b[0;34m(root, concrete_args)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[39mSymbolic tracing API\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39m    GraphModule: a Module created from the recorded operations from ``root``.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    877\u001b[0m tracer \u001b[39m=\u001b[39m Tracer()\n\u001b[0;32m--> 878\u001b[0m graph \u001b[39m=\u001b[39m tracer\u001b[39m.\u001b[39;49mtrace(root, concrete_args)\n\u001b[1;32m    879\u001b[0m name \u001b[39m=\u001b[39m root\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(root, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule) \u001b[39melse\u001b[39;00m root\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    880\u001b[0m \u001b[39mreturn\u001b[39;00m GraphModule(tracer\u001b[39m.\u001b[39mroot, graph, name)\n",
      "File \u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-3.8-4.10.3/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:587\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autowrap_search:\n\u001b[1;32m    586\u001b[0m         _autowrap_check(patcher, module\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autowrap_function_ids)\n\u001b[0;32m--> 587\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_node(\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_arg(fn(\u001b[39m*\u001b[39;49margs)),), {},\n\u001b[1;32m    588\u001b[0m                      type_expr\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__annotations__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    590\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubmodule_paths \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\n",
      "\u001b[1;32m/home/whcui/brainstorm_project/brainstorm/sample/graph/for_loop.ipynb Cell 1\u001b[0m in \u001b[0;36mForLoop.forward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22413130302d3031227d/home/whcui/brainstorm_project/brainstorm/sample/graph/for_loop.ipynb#ch0000000vscode-remote?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, xs: List[torch\u001b[39m.\u001b[39mTensor]):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22413130302d3031227d/home/whcui/brainstorm_project/brainstorm/sample/graph/for_loop.ipynb#ch0000000vscode-remote?line=11'>12</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m xs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22413130302d3031227d/home/whcui/brainstorm_project/brainstorm/sample/graph/for_loop.ipynb#ch0000000vscode-remote?line=12'>13</a>\u001b[0m         xs[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22413130302d3031227d/home/whcui/brainstorm_project/brainstorm/sample/graph/for_loop.ipynb#ch0000000vscode-remote?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m xs\n",
      "File \u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-3.8-4.10.3/lib/python3.8/site-packages/torch/fx/proxy.py:284\u001b[0m, in \u001b[0;36mProxy.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracer\u001b[39m.\u001b[39mcreate_proxy(\u001b[39m'\u001b[39m\u001b[39mcall_function\u001b[39m\u001b[39m'\u001b[39m, assert_fn, (\u001b[39mself\u001b[39m,), {})\n\u001b[1;32m    282\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtracer\u001b[39m.\u001b[39;49mto_bool(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-3.8-4.10.3/lib/python3.8/site-packages/torch/fx/proxy.py:160\u001b[0m, in \u001b[0;36mTracerBase.to_bool\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m@compatibility\u001b[39m(is_backward_compatible\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_bool\u001b[39m(\u001b[39mself\u001b[39m, obj: \u001b[39m'\u001b[39m\u001b[39mProxy\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    155\u001b[0m     \u001b[39m\"\"\"Called when a proxy object is being converted to a boolean, such as\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m    when used in control flow.  Normally we don't know what to do because\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m    we don't know the value of the proxy, but a custom tracer can attach more\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m    information to the graph node using create_node and can choose to return a value.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mraise\u001b[39;00m TraceError(\u001b[39m'\u001b[39m\u001b[39msymbolically traced variables cannot be used as inputs to control flow\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTraceError\u001b[0m: symbolically traced variables cannot be used as inputs to control flow"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "import torch.fx\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ForLoop(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, xs: List[torch.Tensor]):\n",
    "        while xs[0].numel() > 0:\n",
    "            xs[0] = torch.zeros((0, 0))\n",
    "        return xs\n",
    "\n",
    "\n",
    "for_loop_model = ForLoop()\n",
    "s_for_loop_model = torch.fx.symbolic_trace(for_loop_model)\n",
    "# print(s_for_loop_model.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7801,  1.5037,  0.4237, -1.1433,  0.0262, -0.3877,  0.1027, -0.5722,\n",
      "          0.5217,  0.2045]], grad_fn=<AliasBackward0>)\n",
      "graph(%self : __torch__.ForLoop,\n",
      "      %x.1 : Tensor):\n",
      "  %8 : NoneType = prim::Constant()\n",
      "  %2 : int = prim::Constant[value=1]() # /tmp/ipykernel_3032693/2187210996.py:17:30\n",
      "  %12 : int = prim::Constant[value=9223372036854775807]() # /tmp/ipykernel_3032693/2187210996.py:18:8\n",
      "  %15 : int = prim::Constant[value=0]() # /tmp/ipykernel_3032693/2187210996.py:18:31\n",
      "  %5 : Device = prim::device(%x.1)\n",
      "  %7 : int[] = prim::ListConstruct(%2, %2)\n",
      "  %target.1 : Tensor = aten::zeros(%7, %8, %8, %5, %8) # /tmp/ipykernel_3032693/2187210996.py:17:17\n",
      "  %49 : int = aten::numel(%target.1) # /tmp/ipykernel_3032693/2187210996.py:18:14\n",
      "  %50 : bool = aten::gt(%49, %15) # /tmp/ipykernel_3032693/2187210996.py:18:14\n",
      "  %x : Tensor = prim::Loop(%12, %50, %x.1) # /tmp/ipykernel_3032693/2187210996.py:18:8\n",
      "    block0(%18 : int, %x.19 : Tensor):\n",
      "      %scatter : __torch__.brt.routers.app.rand.RandScatterRouter = prim::GetAttr[name=\"scatter\"](%self)\n",
      "      %route_results.1 : Tensor[] = prim::CallMethod[name=\"forward\"](%scatter, %x.19) # /tmp/ipykernel_3032693/2187210996.py:19:28\n",
      "      %target.5 : Tensor = aten::__getitem__(%route_results.1, %15) # /tmp/ipykernel_3032693/2187210996.py:20:21\n",
      "      %moe_decoder : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"moe_decoder\"](%self)\n",
      "      %27 : Tensor = aten::__getitem__(%route_results.1, %15) # /tmp/ipykernel_3032693/2187210996.py:21:33\n",
      "      %x.7 : Tensor = prim::CallMethod[name=\"forward\"](%moe_decoder, %27) # /tmp/ipykernel_3032693/2187210996.py:21:16\n",
      "      %gather : __torch__.brt.routers.router.GatherRouter = prim::GetAttr[name=\"gather\"](%self)\n",
      "      %33 : Tensor = aten::__getitem__(%route_results.1, %2) # /tmp/ipykernel_3032693/2187210996.py:22:32\n",
      "      %34 : Tensor[] = prim::ListConstruct(%x.7, %33)\n",
      "      %x.13 : Tensor = prim::CallMethod[name=\"forward\"](%gather, %34) # /tmp/ipykernel_3032693/2187210996.py:22:16\n",
      "      %14 : int = aten::numel(%target.5) # /tmp/ipykernel_3032693/2187210996.py:18:14\n",
      "      %16 : bool = aten::gt(%14, %15) # /tmp/ipykernel_3032693/2187210996.py:18:14\n",
      "      -> (%16, %x.13)\n",
      "  return (%x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from brt.routers.app import RandScatterRouter\n",
    "from brt.routers import GatherRouter\n",
    "from brt.frontend import symbolize\n",
    "\n",
    "\n",
    "class ForLoop(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scatter = RandScatterRouter(dst_num=2)\n",
    "        self.moe_decoder = nn.Linear(10, 10)\n",
    "        self.gather = GatherRouter(dst_num=2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        target = torch.zeros((1, 1), device=x.device)\n",
    "        while target.numel() > 0:\n",
    "            route_results = self.scatter(x)\n",
    "            target = route_results[0]\n",
    "            x = self.moe_decoder(route_results[0])\n",
    "            x = self.gather([x, route_results[1]])\n",
    "        return x\n",
    "\n",
    "\n",
    "for_loop_model = ForLoop()\n",
    "\n",
    "x = torch.randn(1, 10)\n",
    "y = for_loop_model(x)\n",
    "print(y)\n",
    "s_for_loop_model = torch.jit.script(symbolize(for_loop_model))\n",
    "print(s_for_loop_model.graph)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4914c35dbc1a262acb2241fbfc193aaeb9362d455da2cebdd4b0a1d658dbfd5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
