{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import fx\n",
    "from torch.fx import GraphModule, Graph, Node\n",
    "from torch.utils.benchmark import Timer\n",
    "\n",
    "import brt\n",
    "from brt.runtime import log\n",
    "from brt.runtime import ProtoTensor\n",
    "from brt.runtime.benchmark import profile\n",
    "from brt.router import ScatterRouter, GatherRouter\n",
    "from brt.router.fabric import make_fabric\n",
    "from brt.trace import symbolic_trace, GraphTracer\n",
    "\n",
    "# from brt.trace.graph import symbolic_trace\n",
    "from brt.passes import (\n",
    "    HorizFusePass,\n",
    "    OperatorReorderPass,\n",
    "    DeadPathEliminatePass,\n",
    "    ConstantPropagationPass,\n",
    "    RouterFixPass,\n",
    ")\n",
    "\n",
    "log.set_level(\"BRT\", \"DEBUG\")\n",
    "\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from brt.runtime import BRT_CACHE_PATH\n",
    "\n",
    "sys.path.append(str(BRT_CACHE_PATH.parent / \"benchmark/livesr/\"))\n",
    "# from nas_mdsr import SingleNetwork as nas_mdsr\n",
    "from archs.livesr import LiveSR\n",
    "from dataset import get_dataloader\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "sys.path.append(str(BRT_CACHE_PATH.parent / \"benchmark/msdnet/\"))\n",
    "from msdnet import MSDNet\n",
    "from theshold_inference import threshold_dynamic_evaluate\n",
    "from dataloader import get_dataloaders as msdnet_get_dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_PROFILING = False\n",
    "# IS_PROFILING = True\n",
    "IS_FUSING_HEAD = False\n",
    "IS_FUSING_HEAD = True\n",
    "HOME_PATH = \"/home/lingji/\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSDNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    arch=\"msdnet\",\n",
    "    base=4,\n",
    "    batch_size=256,\n",
    "    benchmark=[\"all_opt\"],\n",
    "    bnFactor=[1, 2, 4, 4],\n",
    "    bottleneck=True,\n",
    "    data=\"ImageNet\",\n",
    "    data_root=HOME_PATH + \"dataset/imagenet\",\n",
    "    decay_rate=0.1,\n",
    "    epochs=90,\n",
    "    evalmode=\"threshold\",\n",
    "    evaluate_from=HOME_PATH\n",
    "    + \"brainstorm_project/brainstorm/benchmark/msdnet/msdnet-step=4-block=5.pth.tar\",\n",
    "    gpu=\"0,1,2,3\",\n",
    "    grFactor=[1, 2, 4, 4],\n",
    "    growthRate=16,\n",
    "    init_routers=True,\n",
    "    lr=0.1,\n",
    "    lr_type=\"multistep\",\n",
    "    momentum=0.9,\n",
    "    nBlocks=5,\n",
    "    nChannels=32,\n",
    "    nScales=4,\n",
    "    num_classes=1000,\n",
    "    optimizer=\"sgd\",\n",
    "    parallel=True,\n",
    "    print_freq=10,\n",
    "    prune=\"max\",\n",
    "    reduction=0.5,\n",
    "    resume=False,\n",
    "    save=HOME_PATH + \"brainstorm_project/brainstorm/benchmark/msdnet/saveresult\",\n",
    "    seed=0,\n",
    "    splits=[\"val\", \"test\"],\n",
    "    start_epoch=0,\n",
    "    step=4,\n",
    "    stepmode=\"even\",\n",
    "    # thresholds=[0.44246858, -1, -1, -1], # 0.5 0.5 0 0\n",
    "    # thresholds=[0.34071380, 0.47392023, 0.37517136, 0.22579938],  # 0.6 0.1 0.1 0.1 0.1\n",
    "    thresholds=[1000000, 100000, 1000000, 100000],  # 0, 0, 0, 0, 1\n",
    "    use_valid=True,\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "msdnet: nn.Module = MSDNet(args, False).eval().cuda()\n",
    "# pretrained_dict = torch.load(HOME_PATH + \"brainstorm_project/brainstorm/benchmark/msdnet/MSDNet.pth\")\n",
    "state_dict = torch.load(\n",
    "    \"/home/lingji/brainstorm_project/brainstorm/benchmark/msdnet/MSDNet.pth\"\n",
    ")\n",
    "# print([k for k, v in msdnet.named_parameters()])\n",
    "# print([k for k, v in state_dict.items()])\n",
    "msdnet.load_state_dict(state_dict)\n",
    "\n",
    "_, val_dataloader, test_dataloader = msdnet_get_dataloaders(args)\n",
    "\n",
    "# print(msdnet)\n",
    "# print(input.shape)\n",
    "\n",
    "\n",
    "def print_load_history(m: nn.Module):\n",
    "    print(\"\")\n",
    "    for subn, subm in m.named_modules():\n",
    "        if isinstance(subm, (ScatterRouter, GatherRouter)):\n",
    "            # print(subm.load_history.shape)\n",
    "            print(subm.load_history)\n",
    "\n",
    "\n",
    "for i, (input, target) in enumerate(test_dataloader):\n",
    "    input = input.cuda()\n",
    "    if i > 100:\n",
    "        break\n",
    "    # if i % 1000 == 0:\n",
    "    #     print_load_history(msdnet)\n",
    "    print(\"*\", end=\"\")\n",
    "    output = msdnet(input)\n",
    "\n",
    "print(\"\")\n",
    "print_load_history(msdnet)\n",
    "\n",
    "for i, (input, target) in enumerate(test_dataloader):\n",
    "    input = input.cuda()\n",
    "    if i == 13:\n",
    "        break\n",
    "\n",
    "y = msdnet(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = []\n",
    "\n",
    "for i, (test_input, target) in enumerate(test_dataloader):\n",
    "    if i < 10:\n",
    "        test_inputs.append(test_input.cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_PROFILING:\n",
    "    profile(lambda: msdnet(input))\n",
    "\n",
    "raw_time = []\n",
    "for test_input in test_inputs:\n",
    "    raw_time.append(\n",
    "        Timer(\n",
    "            f\"model(x)\",\n",
    "            setup=\"import torch; torch.cuda.synchronize()\",\n",
    "            globals={\"model\": msdnet, \"x\": test_input},\n",
    "        )\n",
    "        .timeit(10)\n",
    "        .mean\n",
    "        * 10e6\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gm_msdnet = symbolic_trace(\n",
    "#     msdnet,\n",
    "#     tracing_shape=True,\n",
    "#     sample_inputs={\"x\": input},\n",
    "# )\n",
    "# print(gm_msdnet.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(msdnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminate_pass = DeadPathEliminatePass(msdnet)\n",
    "eliminate_pass.run_on_graph()\n",
    "msdnet_dpe = eliminate_pass.finalize()\n",
    "\n",
    "# constant_propagation_pass = ConstantPropagationPass(\n",
    "#     msdnet, upper_perm_load=args.batch_size * n_batch\n",
    "# )\n",
    "# constant_propagation_pass.run_on_graph()\n",
    "# msdnet = constant_propagation_pass.finalize()\n",
    "\n",
    "operator_reorder_pass = OperatorReorderPass(msdnet_dpe, False)\n",
    "operator_reorder_pass.run_on_graph()\n",
    "msdnet_reorder = operator_reorder_pass.finalize()\n",
    "\n",
    "horiz_fusion_pass = HorizFusePass(\n",
    "    msdnet_reorder,\n",
    "    sample_inputs={\"x\": input},\n",
    "    fusing_head=IS_FUSING_HEAD,\n",
    ")\n",
    "horiz_fusion_pass.run_on_graph()\n",
    "msdnet_hf = horiz_fusion_pass.finalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msdnet_hf.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msdnet_hf.code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in msdnet_hf.graph.nodes:\n",
    "    if node.op == \"call_module\" and node.is_fixed_inout:\n",
    "        submodule = msdnet_hf.get_submodule(node.target)\n",
    "        if not isinstance(submodule, (ScatterRouter, GatherRouter)):\n",
    "            if \"BRT_HF\" not in node.name:\n",
    "                continue\n",
    "            print(f\"{node.target}\")\n",
    "            submodule_input = msdnet_hf.graph._get_output_from_node_or_list(node.args)\n",
    "            print([getattr(ii, \"shape\", None) for ii in submodule_input])\n",
    "            print([ii.is_cuda for ii in submodule_input])\n",
    "            print(submodule._module_name)\n",
    "            print(submodule.cuda_code)\n",
    "            # time.sleep(10000)\n",
    "            break\n",
    "            try:\n",
    "                submodule(*submodule_input)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(submodule_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.fx.passes.graph_drawer import FxGraphDrawer\n",
    "\n",
    "graph_drawer = FxGraphDrawer(msdnet_hf, \"msdnet\")\n",
    "with open(\"msdnet_hfused.svg\", \"wb\") as f:\n",
    "    f.write(graph_drawer.get_dot_graph().create_svg())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msdnet: nn.Module = MSDNet(args, False).eval().cuda()\n",
    "msdnet.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = msdnet(input)\n",
    "hy = msdnet_hf(input)\n",
    "print(torch.allclose(y, hy, rtol=1e-100, atol=1e-2))\n",
    "\n",
    "for i, (input, target) in enumerate(test_dataloader):\n",
    "    input = input.cuda()\n",
    "    if i > 100:\n",
    "        break\n",
    "    y = msdnet(input)\n",
    "    hy = msdnet_hf(input)\n",
    "    print(torch.allclose(y, hy, rtol=1e-100, atol=1e-1))\n",
    "    if not torch.allclose(y, hy, rtol=1e-100, atol=1e-1):\n",
    "        print(torch.sum(torch.abs(y)))\n",
    "        print(torch.sum(torch.abs(y - hy)))\n",
    "        print(torch.max(y - hy))\n",
    "\n",
    "# print(torch.sum(y))\n",
    "# print(torch.sum(y - hy))\n",
    "# print(torch.sum(torch.abs(y)))\n",
    "# print(torch.max(y))\n",
    "# print(torch.max(y - hy))\n",
    "# print(torch.min(torch.abs(y)))\n",
    "# print(torch.min(torch.abs(y - hy)))\n",
    "# print(torch.min(y))\n",
    "# print(torch.min(y - hy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_PROFILING:\n",
    "    profile(lambda: msdnet_hf(input))\n",
    "\n",
    "hf_time = []\n",
    "for test_input in test_inputs:\n",
    "    hf_time.append(\n",
    "        Timer(\n",
    "            f\"model(x)\",\n",
    "            setup=\"import torch; torch.cuda.synchronize()\",\n",
    "            globals={\"model\": msdnet_hf, \"x\": test_input},\n",
    "        )\n",
    "        .timeit(10)\n",
    "        .mean\n",
    "        * 10e6\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup = [rt / hft for rt, hft in zip(raw_time, hf_time)]\n",
    "\n",
    "print(max(speedup))\n",
    "print(min(speedup))\n",
    "print(sum(speedup) / len(speedup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LiveSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "livesr = LiveSR(n_subnets=10, subnet_num_block=3, num_feature=channels).eval().cuda()\n",
    "\n",
    "dataloader = get_dataloader(\n",
    "    str(BRT_CACHE_PATH.parent / \"benchmark/livesr/dataset/cam1/LQ\")\n",
    ")\n",
    "\n",
    "for x in dataloader:\n",
    "    break\n",
    "\n",
    "livesr(x)\n",
    "print(livesr.scatter.load_history)\n",
    "livesr.scatter.load_history = np.array([6, 7, 12, 27, 8, 8, 8, 12, 12, 4], dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(symbolic_trace(livesr).graph)\n",
    "\n",
    "gm_livesr = symbolic_trace(\n",
    "    livesr,\n",
    "    tracing_shape=True,\n",
    "    sample_inputs={\"inputs\": x},\n",
    ")\n",
    "\n",
    "router_fix_pass = RouterFixPass(gm_livesr)\n",
    "router_fix_pass.run_on_graph()\n",
    "gm_livesr = router_fix_pass.finalize()\n",
    "\n",
    "horizontal_fuse_pass = HorizFusePass(gm_livesr, sample_inputs={\"inputs\": x})\n",
    "horizontal_fuse_pass.run_on_graph()\n",
    "gm_livesr = horizontal_fuse_pass.finalize()\n",
    "\n",
    "print(gm_livesr.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = livesr(x)\n",
    "\n",
    "gm_livesr.delete_all_unused_submodules()\n",
    "\n",
    "all_hooks = []\n",
    "target_of_module = {}\n",
    "scatter_outputs = [None]\n",
    "try:\n",
    "    for subn, subm in gm_livesr.named_modules():\n",
    "        if \"classifier\" in subn:\n",
    "            continue\n",
    "        target_of_module[subm] = subn\n",
    "\n",
    "        def print_pre_hook(m: nn.Module, i):\n",
    "            name = target_of_module[m]\n",
    "            print(\n",
    "                f\"{name:50.50} {m._get_name():20} {str(set(ii.__class__.__name__ for ii in i)):30}\"\n",
    "            )\n",
    "\n",
    "        def print_hook(m: nn.Module, i, o):\n",
    "            name = target_of_module[m]\n",
    "            print(\n",
    "                f\"{name:50.50} {m._get_name():20} {str(set(ii.__class__.__name__ for ii in i)):30} \"\n",
    "                f\"{str(set(oo.__class__.__name__ for oo in o)):30} \"\n",
    "            )\n",
    "            # print(\"\\t\\t\", getattr(o, \"shape\", None))\n",
    "            if isinstance(o, (list, tuple)):\n",
    "                for oo in o:\n",
    "                    if isinstance(oo, ProtoTensor):\n",
    "                        # print(\"\\t\\t\", [ootg.squeeze().cpu() for ootg in oo.tag_stack])\n",
    "                        print(\"\\t\\t\", oo.shape)\n",
    "            if name == \"gather.fabric\":\n",
    "                for oo in i[0]:\n",
    "                    if isinstance(oo, ProtoTensor):\n",
    "                        # print(\"\\t\\t\", [ootg.squeeze().cpu() for ootg in oo.tag_stack])\n",
    "                        print(\"\\t\\t\", oo.shape)\n",
    "\n",
    "        all_hooks.append(subm.register_forward_hook(print_hook))\n",
    "        # all_hooks.append(subm.register_forward_pre_hook(print_pre_hook))\n",
    "\n",
    "        def get_scatter_outputs(m, i, o):\n",
    "            scatter_outputs[0] = o\n",
    "\n",
    "        if isinstance(subm, ScatterRouter):\n",
    "            all_hooks.append(subm.register_forward_hook(get_scatter_outputs))\n",
    "\n",
    "    hy = gm_livesr(x)\n",
    "finally:\n",
    "    for hook in all_hooks:\n",
    "        hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = livesr(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = gm_livesr(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(hy.shape)\n",
    "\n",
    "print(torch.allclose(y, hy, rtol=1e-100, atol=1e-2))\n",
    "print(torch.sum(y))\n",
    "print(torch.sum(y - hy))\n",
    "print(torch.sum(torch.abs(y)))\n",
    "print(torch.sum(torch.abs(y - hy)))\n",
    "print(torch.max(y))\n",
    "print(torch.max(y - hy))\n",
    "print(torch.min(torch.abs(y)))\n",
    "print(torch.min(torch.abs(y - hy)))\n",
    "print(torch.min(y))\n",
    "print(torch.min(y - hy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_time = (\n",
    "    Timer(\n",
    "        f\"model(x)\",\n",
    "        setup=\"import torch; torch.cuda.synchronize()\",\n",
    "        globals={\"model\": livesr, \"x\": x},\n",
    "    )\n",
    "    .timeit(100)\n",
    "    .mean\n",
    "    * 10e6\n",
    ")\n",
    "\n",
    "hf_time = (\n",
    "    Timer(\n",
    "        f\"model(x)\",\n",
    "        setup=\"import torch; torch.cuda.synchronize()\",\n",
    "        globals={\"model\": gm_livesr, \"x\": x},\n",
    "    )\n",
    "    .timeit(100)\n",
    "    .mean\n",
    "    * 10e6\n",
    ")\n",
    "\n",
    "print(raw_time)\n",
    "print(hf_time)\n",
    "print(raw_time / hf_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
