{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting logger for brainstorm.frontend to DEBUG level\n",
      "setting logger for brainstorm.backend to DEBUG level\n",
      "setting logger for brainstorm.ir to DEBUG level\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: prim::GetAttr\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: prim::Constant\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: prim::Constant\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: prim::GetAttr\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.frontend/MainThread) building brt.router RandomScatterRouter, m_attrs: {'route_num': 2}\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: __torch__.brt.router.scatter_router.RandomScatterRouter\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: prim::TupleUnpack\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: prim::GetAttr\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: aten::__getitem__\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: __torch__.torch.nn.modules.linear.Linear\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: prim::GetAttr\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: aten::__getitem__\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: __torch__.torch.nn.modules.linear.Linear\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: prim::GetAttr\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: prim::ListConstruct\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.frontend/MainThread) building brt.router RandomGatherRouter, m_attrs: {'route_num': 2}\n",
      "[2022-05-02 12:21:03] DEBUG (brainstorm.ir/MainThread) find subclass of pytorch operation: __torch__.brt.router.gather_router.RandomGatherRouter\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from brt.common import log\n",
    "import brt\n",
    "import brt.nn as nn\n",
    "from brt.router import RandomScatterRouter, RandomGatherRouter\n",
    "from brt.frontend import build_graph, flatten_model_graph\n",
    "log.set_level(\"frontend\", \"DEBUG\")\n",
    "log.set_level(\"backend\", \"DEBUG\")\n",
    "log.set_level(\"ir\", \"DEBUG\")\n",
    "\n",
    "\n",
    "@brt.netlet\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scatter_router = RandomScatterRouter(route_num=2)\n",
    "        self.expert1 = nn.Linear(10, 10)\n",
    "        self.expert2 = nn.Linear(10, 10)\n",
    "        self.gather_router = RandomGatherRouter(route_num=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        route_results, reverse_indice, reverse_shape = self.scatter_router(x)\n",
    "        x_0 = self.expert1(route_results[0])\n",
    "        x_1 = self.expert2(route_results[1])\n",
    "        x = self.gather_router([x_0, x_1], reverse_indice, reverse_shape)\n",
    "        return x\n",
    "\n",
    "@brt.domain\n",
    "class MoEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.moe = MoE()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.moe(x)\n",
    "\n",
    "\n",
    "moe_model = MoEModel()\n",
    "script_moe_model = torch.jit.script(moe_model)\n",
    "sm_graph = script_moe_model.moe.graph\n",
    "# print(sm_graph)\n",
    "# for node in sm_graph.nodes():\n",
    "#     if node.kind() == \"prim::PythonOp\":\n",
    "#         print(node, node.inputsAt(0).debugName())\n",
    "    # print(node.s(\"name\"))\n",
    "    # print(node.inputsAt(0).debugName())\n",
    "    # _val = getattr(moe_model, node.s(\"name\"))\n",
    "    # print(_val)\n",
    "    # print(type(_val))\n",
    "# normal_model_ir = build_graph(normal_model)\n",
    "ir_moe_model = build_graph(moe_model)\n",
    "flattened_ir_moe_model = flatten_model_graph(ir_moe_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: []\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _Constant2, node_name: _Constant2, inputs: [], inputs_value: []\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: []\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _Constant3, node_name: _Constant3, inputs: [], inputs_value: []\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\")), 0), tail=(Node(id=5, name=_model__moe__scatter_router, python_name=moe.scatter_router, label=None, operation=ModuleOperator(type=\"__torch__.brt.router.scatter_router.RandomScatterRouter\", route_num=2)), None))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _scatter_router, node_name: _scatter_router, inputs: ['x__1'], inputs_value: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=5, name=_model__moe__scatter_router, python_name=moe.scatter_router, label=None, operation=ModuleOperator(type=\"__torch__.brt.router.scatter_router.RandomScatterRouter\", route_num=2)), None), tail=(Node(id=6, name=_model__moe__TupleUnpack6, python_name=None, label=None, operation=PrimTupleUnpack(type=\"prim::TupleUnpack\")), None))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _TupleUnpack6, node_name: _TupleUnpack6, inputs: ['_scatter_router'], inputs_value: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=6, name=_model__moe__TupleUnpack6, python_name=None, label=None, operation=PrimTupleUnpack(type=\"prim::TupleUnpack\")), 0), tail=(Node(id=8, name=_model__moe__aten____getitem__8, python_name=moe.__getitem__, label=None, operation=AtenGetitem(type=\"aten::__getitem__\")), 0)), Edge(head=(Node(id=2, name=_model__moe__Constant2, python_name=None, label=None, operation=PrimConstant(type=\"prim::Constant\", type='int', value=0)), None), tail=(Node(id=8, name=_model__moe__aten____getitem__8, python_name=moe.__getitem__, label=None, operation=AtenGetitem(type=\"aten::__getitem__\")), 1))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [0, 1]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _aten____getitem__8, node_name: _aten____getitem__8, inputs: ['_TupleUnpack6[0]', '_Constant2'], inputs_value: [None, 0]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=6, name=_model__moe__TupleUnpack6, python_name=None, label=None, operation=PrimTupleUnpack(type=\"prim::TupleUnpack\")), 0), tail=(Node(id=11, name=_model__moe__aten____getitem__10, python_name=moe.__getitem__, label=None, operation=AtenGetitem(type=\"aten::__getitem__\")), 0)), Edge(head=(Node(id=3, name=_model__moe__Constant3, python_name=None, label=None, operation=PrimConstant(type=\"prim::Constant\", type='int', value=1)), None), tail=(Node(id=11, name=_model__moe__aten____getitem__10, python_name=moe.__getitem__, label=None, operation=AtenGetitem(type=\"aten::__getitem__\")), 1))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [0, 1]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _aten____getitem__10, node_name: _aten____getitem__10, inputs: ['_TupleUnpack6[0]', '_Constant3'], inputs_value: [None, 1]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=8, name=_model__moe__aten____getitem__8, python_name=moe.__getitem__, label=None, operation=AtenGetitem(type=\"aten::__getitem__\")), None), tail=(Node(id=9, name=_model__moe__expert1, python_name=moe.expert1, label=None, operation=ModuleOperator(type=\"__torch__.torch.nn.modules.linear.Linear\", in_features=10, out_features=10)), None))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _expert1, node_name: _expert1, inputs: ['_aten____getitem__8'], inputs_value: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=11, name=_model__moe__aten____getitem__10, python_name=moe.__getitem__, label=None, operation=AtenGetitem(type=\"aten::__getitem__\")), None), tail=(Node(id=12, name=_model__moe__expert2, python_name=moe.expert2, label=None, operation=ModuleOperator(type=\"__torch__.torch.nn.modules.linear.Linear\", in_features=10, out_features=10)), None))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _expert2, node_name: _expert2, inputs: ['_aten____getitem__10'], inputs_value: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=9, name=_model__moe__expert1, python_name=moe.expert1, label=None, operation=ModuleOperator(type=\"__torch__.torch.nn.modules.linear.Linear\", in_features=10, out_features=10)), None), tail=(Node(id=14, name=_model__moe__ListConstruct12, python_name=None, label=None, operation=PrimListConstruct(type=\"prim::ListConstruct\")), 0)), Edge(head=(Node(id=12, name=_model__moe__expert2, python_name=moe.expert2, label=None, operation=ModuleOperator(type=\"__torch__.torch.nn.modules.linear.Linear\", in_features=10, out_features=10)), None), tail=(Node(id=14, name=_model__moe__ListConstruct12, python_name=None, label=None, operation=PrimListConstruct(type=\"prim::ListConstruct\")), 1))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [0, 1]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _ListConstruct12, node_name: _ListConstruct12, inputs: ['_expert1', '_expert2'], inputs_value: [None, None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=14, name=_model__moe__ListConstruct12, python_name=None, label=None, operation=PrimListConstruct(type=\"prim::ListConstruct\")), None), tail=(Node(id=15, name=_model__moe__gather_router, python_name=moe.gather_router, label=None, operation=ModuleOperator(type=\"__torch__.brt.router.gather_router.RandomGatherRouter\", route_num=2)), 0)), Edge(head=(Node(id=6, name=_model__moe__TupleUnpack6, python_name=None, label=None, operation=PrimTupleUnpack(type=\"prim::TupleUnpack\")), 1), tail=(Node(id=15, name=_model__moe__gather_router, python_name=moe.gather_router, label=None, operation=ModuleOperator(type=\"__torch__.brt.router.gather_router.RandomGatherRouter\", route_num=2)), 1)), Edge(head=(Node(id=6, name=_model__moe__TupleUnpack6, python_name=None, label=None, operation=PrimTupleUnpack(type=\"prim::TupleUnpack\")), 2), tail=(Node(id=15, name=_model__moe__gather_router, python_name=moe.gather_router, label=None, operation=ModuleOperator(type=\"__torch__.brt.router.gather_router.RandomGatherRouter\", route_num=2)), 2))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [0, 1, 2]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _gather_router, node_name: _gather_router, inputs: ['_ListConstruct12', '_TupleUnpack6[1]', '_TupleUnpack6[2]'], inputs_value: [None, None, None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=15, name=_model__moe__gather_router, python_name=moe.gather_router, label=None, operation=ModuleOperator(type=\"__torch__.brt.router.gather_router.RandomGatherRouter\", route_num=2)), None), tail=(Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\")), None))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\")), 0), tail=(Node(id=16, name=_model__moe, python_name=moe, label=None, operation=Cell(type=\"_cell\")), None))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) submodule_name: _moe, node_name: _moe, inputs: ['x__1'], inputs_value: [None]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) sorted_incoming_edges: [Edge(head=(Node(id=16, name=_model__moe, python_name=moe, label=None, operation=Cell(type=\"_cell\")), None), tail=(Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\")), None))]\n",
      "[2022-05-02 12:21:48] DEBUG (brainstorm.backend/MainThread) all tail_slots are None: [None]\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "\n",
      "import brt.nn\n",
      "\n",
      "import brt\n",
      "import torch\n",
      "\n",
      "\n",
      "class _model__moe(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self._scatter_router = brt.router.scatter_router.RandomScatterRouter(route_num=2)\n",
      "        self._expert1 = torch.nn.modules.linear.Linear(in_features=10, out_features=10)\n",
      "        self._expert2 = torch.nn.modules.linear.Linear(in_features=10, out_features=10)\n",
      "        self._gather_router = brt.router.gather_router.RandomGatherRouter(route_num=2)\n",
      "        self._mapping_ = {'_scatter_router': 'moe.scatter_router', '_expert1': 'moe.expert1', '_expert2': 'moe.expert2', '_gather_router': 'moe.gather_router'}\n",
      "\n",
      "    def forward(self, x__1):\n",
      "        _Constant2 = 0\n",
      "        _Constant3 = 1\n",
      "        _scatter_router = self._scatter_router(x__1)\n",
      "        _TupleUnpack6 = _scatter_router\n",
      "        _aten____getitem__8 = _TupleUnpack6[0][_Constant2]\n",
      "        _aten____getitem__10 = _TupleUnpack6[0][_Constant3]\n",
      "        _expert1 = self._expert1(_aten____getitem__8)\n",
      "        _expert2 = self._expert2(_aten____getitem__10)\n",
      "        _ListConstruct12 = [_expert1, _expert2]\n",
      "        _gather_router = self._gather_router(_ListConstruct12, _TupleUnpack6[1], _TupleUnpack6[2])\n",
      "        return _gather_router\n",
      "\n",
      "\n",
      "\n",
      "class _model(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self._moe = _model__moe()\n",
      "        self._mapping_ = {'_moe': 'moe'}\n",
      "\n",
      "    def forward(self, x__1):\n",
      "        _moe = self._moe(x__1)\n",
      "        return _moe\n"
     ]
    }
   ],
   "source": [
    "from brt.backend.pytorch import model_to_script\n",
    "\n",
    "model_script = model_to_script(ir_moe_model)\n",
    "print(model_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-1.1668,  4.0991, -2.0578,  4.3479,  5.3001, -0.1832, -1.3333,  9.3435,\n",
      "         -6.1432, -0.5831]], grad_fn=<AddmmBackward0>), tensor([[ 3.9222,  1.4431, -0.2387,  1.0776,  0.0810,  1.5783,  1.2412,  0.8928,\n",
      "          1.4979, -1.1245]], grad_fn=<AddmmBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import brt.nn\n",
    "\n",
    "import torch\n",
    "import brt\n",
    "\n",
    "\n",
    "class m_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._moe__scatter_router = brt.router.scatter_router.RandomScatterRouter(route_num=2)\n",
    "        self._moe__expert2 = torch.nn.modules.linear.Linear(in_features=10, out_features=10)\n",
    "        self._moe__expert1 = torch.nn.modules.linear.Linear(in_features=10, out_features=10)\n",
    "        self._moe__gather_router = brt.router.gather_router.RandomGatherRouter(route_num=2)\n",
    "        self._mapping_ = {'_moe__scatter_router': None, '_moe__expert2': None, '_moe__expert1': None, '_moe__gather_router': None}\n",
    "\n",
    "    def forward(self, x__1):\n",
    "        _moe__Constant2 = 0\n",
    "        _moe__Constant3 = 1\n",
    "        _moe__scatter_router = self._moe__scatter_router(x__1)\n",
    "        _moe__TupleUnpack6 = _moe__scatter_router\n",
    "        _moe__aten____getitem__10 = _moe__TupleUnpack6[0][_moe__Constant3]\n",
    "        _moe__aten____getitem__8 = _moe__TupleUnpack6[0][_moe__Constant2]\n",
    "        _moe__expert2 = self._moe__expert2(_moe__aten____getitem__10)\n",
    "        _moe__expert1 = self._moe__expert1(_moe__aten____getitem__8)\n",
    "        _moe__ListConstruct12 = [_moe__expert1, _moe__expert2]\n",
    "        _moe__gather_router = self._moe__gather_router(_moe__ListConstruct12, _moe__TupleUnpack6[1], _moe__TupleUnpack6[2])\n",
    "        return _moe__gather_router\n",
    "    \n",
    "moe = m_model()\n",
    "x = torch.Tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "x = moe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typing.Tuple[torch.Tensor, typing.Union[torch.Tensor, NoneType]]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "missing ), unterminated subpattern at position 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2740831/1671495601.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"typing.Tuple\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr',\\s*(?=[^]]*(?:[|$])'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;34m',(?=[^}]*(?:{|$))'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/re.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(pattern, string, maxsplit, flags)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     of the list.\"\"\"\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, pattern)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0;32m--> 420\u001b[0;31m                            not nested and not items))\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    734\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m                         raise source.error(\"missing ), unterminated subpattern\",\n\u001b[0;32m--> 736\u001b[0;31m                                            source.tell() - start)\n\u001b[0m\u001b[1;32m    737\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                         \u001b[0msubpatternappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASSERT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: missing ), unterminated subpattern at position 4"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from typing import List, Tuple\n",
    "import inspect\n",
    "import re\n",
    "\n",
    "def fwd(x: int) -> Tuple[int, int, int]:\n",
    "    return 1, 2, 3\n",
    "\n",
    "\n",
    "fwd_sig = inspect.signature(nn.MultiheadAttention.forward)\n",
    "x = str(fwd_sig.return_annotation)\n",
    "print(x)\n",
    "if x.startswith(\"typing.Tuple\"):\n",
    "    x = x[len(\"typing.Tuple\") + 1 : -1]\n",
    "    print\n",
    "    s = re.split(r',\\s*(?=[^]]*(?:[|$])', x) \n",
    "    ',(?=[^}]*(?:{|$))'\n",
    "    print(s)\n",
    "    ret_n = len(s)\n",
    "else:\n",
    "    ret_n = 1\n",
    "print(ret_n)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "849bd15258cbc1fdb3dc8c930a1445a9f672620f82bbd55fbc814541035aa795"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
