{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unwrap_redundant_netlet due to top_graph\n",
      "unwrap_redundant_netlet due to no router\n",
      "unwrap_redundant_netlet due to no router\n",
      "unwrap_redundant_netlet due to no router\n",
      "tensor([-1.8560, -1.4745, -2.0467, -0.9605, -0.9353,  1.0686, -2.4302,  0.2452,\n",
      "         0.0262, -0.3079], grad_fn=<AddBackward0>)\n",
      "graph(%self : __torch__.brt.primitive.___torch_mangle_18.wrapper,\n",
      "      %x.1 : Tensor):\n",
      "  %linear1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%self)\n",
      "  %6 : Function = prim::Constant[name=\"linear\"]()\n",
      "  %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%linear1)\n",
      "  %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%linear1)\n",
      "  %x.5 : Tensor = aten::linear(%x.1, %weight.1, %bias.1) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "  %linear2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%self)\n",
      "  %10 : Function = prim::Constant[name=\"linear\"]()\n",
      "  %weight : Tensor = prim::GetAttr[name=\"weight\"](%linear2)\n",
      "  %bias : Tensor = prim::GetAttr[name=\"bias\"](%linear2)\n",
      "  %x.9 : Tensor = aten::linear(%x.5, %weight, %bias) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "  return (%x.9)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import brt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "@brt.top_graph\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(10, 10)\n",
    "        self.linear2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "simple_net = SimpleNet()\n",
    "\n",
    "x = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "x = simple_net(x)\n",
    "print(x)\n",
    "script_simple_net = torch.jit.script(simple_net)\n",
    "simple_net_inlined_graph = script_simple_net.inlined_graph\n",
    "print(simple_net_inlined_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object Linear(in_features=10, out_features=10, bias=True) needs to be serializable but `trace_kwargs` is not available. If it is a built-in module (like Conv2d), please import it from retiarii.nn. If it is a customized module, please to decorate it with @basic_unit. For other complex objects (e.g., trainer, optimizer, dataset, dataloader), try to use @nni.trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1894377/658047933.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretiarii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_to_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretiarii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodegen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_pytorch_script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_ir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_simple_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_ir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/converter/graph_gen.py\u001b[0m in \u001b[0;36mconvert_to_graph\u001b[0;34m(script_module, module, converter, **kwargs)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m     \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/converter/graph_gen.py\u001b[0m in \u001b[0;36mconvert_module\u001b[0;34m(self, script_module, module, module_name, ir_model)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \"\"\"\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/converter/graph_gen.py\u001b[0m in \u001b[0;36m_convert_module\u001b[0;34m(self, script_module, module, module_name, module_python_name, ir_model)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;31m# handle graph nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         self.handle_graph_nodes(script_module, sm_graph, module,\n\u001b[0;32m--> 653\u001b[0;31m                                 module_name, module_python_name, ir_model, ir_graph)\n\u001b[0m\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefine_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/converter/graph_gen.py\u001b[0m in \u001b[0;36mhandle_graph_nodes\u001b[0;34m(self, script_module, sm_graph, module, module_name, module_python_name, ir_model, ir_graph, shared_module_index)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msm_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             \u001b[0mhandle_single_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode_index\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/converter/graph_gen.py\u001b[0m in \u001b[0;36mhandle_single_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \"\"\"\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'prim::CallMethod'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mhandle_function_callmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'prim::CallFunction'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0mfunc_type_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_mangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputsAt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/converter/graph_gen.py\u001b[0m in \u001b[0;36mhandle_function_callmethod\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    324\u001b[0m                                                                  \u001b[0msubmodule_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                                                                  \u001b[0msubmodule_full_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_python_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                                                                  ir_model)\n\u001b[0m\u001b[1;32m    327\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0;31m# %8 : __torch__.nni.retiarii.model_apis.nn.___torch_mangle_37.ModuleList = prim::GetAttr[name=\"cells\"](%self)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/converter/graph_gen.py\u001b[0m in \u001b[0;36m_convert_module\u001b[0;34m(self, script_module, module, module_name, module_python_name, ir_model)\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0moriginal_type_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODULE_EXCEPT_LIST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;31m# this is a basic module from pytorch, no need to parse its graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mm_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_init_parameters_or_fail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_nni_basic_unit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;31m# this module is marked as serialize, won't continue to parse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/serializer.py\u001b[0m in \u001b[0;36mget_init_parameters_or_fail\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_traceable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     raise ValueError(f'Object {obj} needs to be serializable but `trace_kwargs` is not available. '\n\u001b[0m\u001b[1;32m     22\u001b[0m                      \u001b[0;34m'If it is a built-in module (like Conv2d), please import it from retiarii.nn. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                      \u001b[0;34m'If it is a customized module, please to decorate it with @basic_unit. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Object Linear(in_features=10, out_features=10, bias=True) needs to be serializable but `trace_kwargs` is not available. If it is a built-in module (like Conv2d), please import it from retiarii.nn. If it is a customized module, please to decorate it with @basic_unit. For other complex objects (e.g., trainer, optimizer, dataset, dataloader), try to use @nni.trace."
     ]
    }
   ],
   "source": [
    "from nni.retiarii.converter import convert_to_graph\n",
    "from nni.retiarii.codegen import model_to_pytorch_script\n",
    "model_ir = convert_to_graph(script_simple_net, simple_net)\n",
    "\n",
    "for node in model_ir.get_nodes():\n",
    "    print(node)\n",
    "\n",
    "print(\"-----------------\")\n",
    "\n",
    "for cell_node in model_ir.get_cell_nodes():\n",
    "    print(cell_node)\n",
    "\n",
    "model_code = model_to_pytorch_script(model_ir)\n",
    "print(model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unwrap_redundant_netlet due to top_graph\n",
      "unwrap_redundant_netlet due to no router\n",
      "unwrap_redundant_netlet due to no router\n",
      "unwrap_redundant_netlet due to no router\n",
      "unwrap_redundant_netlet due to no router\n",
      "unwrap_redundant_netlet due to no router\n",
      "using brt_forward\n",
      "using brt_forward\n",
      "tensor([[ 8.0769,  1.7423, -7.9711, -0.3013,  3.9045, -1.5637,  6.9472, -0.1561,\n",
      "         -6.9773,  2.2685],\n",
      "        [ 8.0769,  1.7423, -7.9711, -0.3013,  3.9045, -1.5637,  6.9472, -0.1561,\n",
      "         -6.9773,  2.2685]], grad_fn=<ViewBackward0>)\n",
      "graph(%self : __torch__.brt.primitive.___torch_mangle_8.wrapper,\n",
      "      %x.1 : Tensor):\n",
      "  %moe : __torch__.___torch_mangle_7.MoE = prim::GetAttr[name=\"moe\"](%self)\n",
      "  %4 : Function = prim::Constant[name=\"linear\"]()\n",
      "  %5 : int = prim::Constant[value=1]() # /tmp/ipykernel_1894377/268797626.py:18:41\n",
      "  %6 : int = prim::Constant[value=0]() # /tmp/ipykernel_1894377/268797626.py:17:41\n",
      "  %scatter_router : __torch__.brt.router.scatter_router.RandomScatterRouter = prim::GetAttr[name=\"scatter_router\"](%moe)\n",
      "  %8 : (Tensor, Tensor, Tensor) = ^forward()(%scatter_router, %x.1) # /tmp/ipykernel_1894377/268797626.py:16:54\n",
      "  %route_results.1 : Tensor, %reverse_indice.1 : Tensor, %origin_shape.1 : Tensor = prim::TupleUnpack(%8)\n",
      "  %expert1 : __torch__.brt.primitive.wrapper = prim::GetAttr[name=\"expert1\"](%moe)\n",
      "  %13 : Tensor = aten::select(%route_results.1, %6, %6) # /tmp/ipykernel_1894377/268797626.py:17:27\n",
      "  %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%expert1)\n",
      "  %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%expert1)\n",
      "  %x_0.1 : Tensor = aten::linear(%13, %weight.1, %bias.1) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "  %expert2 : __torch__.brt.primitive.wrapper = prim::GetAttr[name=\"expert2\"](%moe)\n",
      "  %18 : Tensor = aten::select(%route_results.1, %6, %5) # /tmp/ipykernel_1894377/268797626.py:18:27\n",
      "  %weight : Tensor = prim::GetAttr[name=\"weight\"](%expert2)\n",
      "  %bias : Tensor = prim::GetAttr[name=\"bias\"](%expert2)\n",
      "  %x_1.1 : Tensor = aten::linear(%18, %weight, %bias) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "  %gather_router : __torch__.brt.router.gather_router.RandomGatherRouter = prim::GetAttr[name=\"gather_router\"](%moe)\n",
      "  %x.5 : Tensor = ^forward()(%gather_router, %reverse_indice.1, %origin_shape.1, %x_0.1, %x_1.1) # /tmp/ipykernel_1894377/268797626.py:19:12\n",
      "  return (%x.5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import brt\n",
    "import brt.nn as nn\n",
    "from brt.router import RandomScatterRouter, RandomGatherRouter\n",
    "\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scatter_router = RandomScatterRouter(route_num=2)\n",
    "        self.expert1 = nn.Linear(10, 10)\n",
    "        self.expert2 = nn.Linear(10, 10)\n",
    "        self.gather_router = RandomGatherRouter(route_num=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        route_results, reverse_indice, origin_shape = self.scatter_router(x)\n",
    "        x_0 = self.expert1(route_results[0])\n",
    "        x_1 = self.expert2(route_results[1])\n",
    "        x = self.gather_router(\n",
    "            reverse_indice,\n",
    "            origin_shape,\n",
    "            x_0,\n",
    "            x_1,\n",
    "        )\n",
    "        return x\n",
    "\n",
    "\n",
    "@brt.top_graph\n",
    "@brt.netlet\n",
    "class MoEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.moe = MoE()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.moe(x)\n",
    "\n",
    "\n",
    "moe_model = MoEModel()\n",
    "\n",
    "x = torch.Tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "# model.cuda()\n",
    "y = 10\n",
    "z = moe_model(x)\n",
    "print(z)\n",
    "\n",
    "\n",
    "# model.brt_script(True)\n",
    "script_moe_model = torch.jit.script(moe_model)\n",
    "print(script_moe_model.inlined_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\"))\n",
      "Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\"))\n",
      "Node(id=114, name=_model__moe__expert1__Attr10, python_name=None, label=None, operation=PrimGetAttr(type=\"prim::GetAttr\", name='weight', input='self', value=None))\n",
      "Node(id=115, name=_model__moe__expert1__Attr11, python_name=None, label=None, operation=PrimGetAttr(type=\"prim::GetAttr\", name='bias', input='self', value=None))\n",
      "Node(id=116, name=_model__moe__expert1__linear12, python_name=moe.expert1.linear, label=None, operation=FunctionalOperator(type=\"Function.linear\"))\n",
      "Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\"))\n",
      "Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\"))\n",
      "Node(id=121, name=_model__moe__expert2__Attr16, python_name=None, label=None, operation=PrimGetAttr(type=\"prim::GetAttr\", name='weight', input='self', value=None))\n",
      "Node(id=122, name=_model__moe__expert2__Attr17, python_name=None, label=None, operation=PrimGetAttr(type=\"prim::GetAttr\", name='bias', input='self', value=None))\n",
      "Node(id=123, name=_model__moe__expert2__linear18, python_name=moe.expert2.linear, label=None, operation=FunctionalOperator(type=\"Function.linear\"))\n",
      "Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\"))\n",
      "Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\"))\n",
      "Node(id=106, name=_model__moe__Constant2, python_name=None, label=None, operation=PrimConstant(type=\"prim::Constant\", type='int', value=0))\n",
      "Node(id=107, name=_model__moe__Constant3, python_name=None, label=None, operation=PrimConstant(type=\"prim::Constant\", type='int', value=1))\n",
      "Node(id=108, name=_model__moe__Attr4, python_name=None, label=None, operation=PrimGetAttr(type=\"prim::GetAttr\", name='scatter_router', input='self', value=None))\n",
      "Node(id=109, name=_model__moe__prim__PythonOp5, python_name=None, label=None, operation=PyTorchOperation(type=\"prim::PythonOp\"))\n",
      "Node(id=110, name=_model__moe__TupleUnpack6, python_name=None, label=None, operation=PrimTupleUnpack(type=\"prim::TupleUnpack\"))\n",
      "Node(id=112, name=_model__moe__aten__select8, python_name=moe.select, label=None, operation=TensorOps(type=\"aten::select\"))\n",
      "Node(id=117, name=_model__moe__expert1, python_name=moe.expert1, label=None, operation=Cell(type=\"_cell\"))\n",
      "Node(id=119, name=_model__moe__aten__select14, python_name=moe.select, label=None, operation=TensorOps(type=\"aten::select\"))\n",
      "Node(id=124, name=_model__moe__expert2, python_name=moe.expert2, label=None, operation=Cell(type=\"_cell\"))\n",
      "Node(id=125, name=_model__moe__Attr19, python_name=None, label=None, operation=PrimGetAttr(type=\"prim::GetAttr\", name='gather_router', input='self', value=None))\n",
      "Node(id=126, name=_model__moe__prim__PythonOp20, python_name=None, label=None, operation=PyTorchOperation(type=\"prim::PythonOp\"))\n",
      "Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\"))\n",
      "Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\"))\n",
      "Node(id=127, name=_model__moe, python_name=moe, label=None, operation=Cell(type=\"_cell\"))\n",
      "-----------------\n",
      "Node(id=117, name=_model__moe__expert1, python_name=moe.expert1, label=None, operation=Cell(type=\"_cell\"))\n",
      "Node(id=124, name=_model__moe__expert2, python_name=moe.expert2, label=None, operation=Cell(type=\"_cell\"))\n",
      "Node(id=127, name=_model__moe, python_name=moe, label=None, operation=Cell(type=\"_cell\"))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "unsupported operation type: prim::PythonOp ? None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1894377/3209371836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_pytorch_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/codegen/pytorch.py\u001b[0m in \u001b[0;36mmodel_to_pytorch_script\u001b[0;34m(model, placement)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtotal_pkgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mimport_pkgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_to_pytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtotal_pkgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_pkgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/codegen/pytorch.py\u001b[0m in \u001b[0;36mgraph_to_pytorch_model\u001b[0;34m(graph_name, graph, placement)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'shared'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0msubmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_variable_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0medge_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_forward_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/operation.py\u001b[0m in \u001b[0;36mto_forward_code\u001b[0;34m(self, field, output, inputs, inputs_value)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not supposed to have aten::slice operation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'unsupported operation type: {self.type} ? {self._to_class_name()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unsupported operation type: prim::PythonOp ? None"
     ]
    }
   ],
   "source": [
    "from nni.retiarii.converter import convert_to_graph\n",
    "from nni.retiarii.codegen import model_to_pytorch_script\n",
    "model_ir = convert_to_graph(script_moe_model, moe_model)\n",
    "\n",
    "for node in model_ir.get_nodes():\n",
    "    print(node)\n",
    "\n",
    "print(\"-----------------\")\n",
    "\n",
    "for cell_node in model_ir.get_cell_nodes():\n",
    "    print(cell_node)\n",
    "\n",
    "model_code = model_to_pytorch_script(model_ir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, use_memory_efficient):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.use_memory_efficient = use_memory_efficient\n",
    "\n",
    "    @torch.jit.ignore(drop=True)\n",
    "    def memory_efficient(self, x):\n",
    "        import pdb\n",
    "\n",
    "        pdb.set_trace()\n",
    "        return x + 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use not-yet-scriptable memory efficient mode\n",
    "        if self.use_memory_efficient:\n",
    "            return self.memory_efficient(x)\n",
    "        else:\n",
    "            return x + 10\n",
    "\n",
    "\n",
    "m = torch.jit.script(MyModule(use_memory_efficient=False))\n",
    "# m.save(\"m.pt\")\n",
    "\n",
    "m = torch.jit.script(MyModule(use_memory_efficient=True))\n",
    "# exception raised\n",
    "print(m.inlined_graph)\n",
    "# m.save(\"m.pt\")\n",
    "# m(torch.rand(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6597,  1.9257, -1.5097, -4.6707, -0.4496,  3.1321,  1.4132,  1.1851,\n",
      "         0.9164,  0.7567], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3143, -1.6946, -0.8486,  0.4667,  0.3905, -0.5602,  0.1592, -0.5632,\n",
      "         1.1540, -1.0938], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import brt.nn as nn\n",
    "import torch\n",
    "from brt import netlet, top_graph\n",
    "from brt.primitive import unwrap_netlet, unwrap_redundant_netlet\n",
    "\n",
    "@top_graph\n",
    "@netlet\n",
    "class RedundantModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "redundant_model = RedundantModel()\n",
    "x = torch.Tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "x = redundant_model(x)\n",
    "print(x)\n",
    "\n",
    "# assert redundant_model._netlet_tag == True, \"netlet_tag is not set\"\n",
    "# assert redundant_model._top_graph == True, \"top_graph is not set\"\n",
    "\n",
    "redundant_model = unwrap_redundant_netlet(redundant_model)\n",
    "\n",
    "x = redundant_model(x)\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "\n",
      "import nni.retiarii.nn.pytorch\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class _model__conv_bn_relu(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self._0 = torch.nn.modules.conv.Conv2d(in_channels=3, out_channels=3, kernel_size=1, stride=1, bias=False)\n",
      "        self._1 = torch.nn.modules.batchnorm.BatchNorm2d(num_features=3)\n",
      "        self._2 = torch.nn.modules.activation.ReLU(inplace=False)\n",
      "        self._mapping_ = {'_0': 'conv_bn_relu.0', '_1': 'conv_bn_relu.1', '_2': 'conv_bn_relu.2'}\n",
      "\n",
      "    def forward(self, input__1):\n",
      "        _0 = self._0(input__1)\n",
      "        _1 = self._1(_0)\n",
      "        _2 = self._2(_1)\n",
      "        return _2\n",
      "\n",
      "\n",
      "\n",
      "class _model(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self._conv_bn_relu = _model__conv_bn_relu()\n",
      "        self._mapping_ = {'_conv_bn_relu': 'conv_bn_relu'}\n",
      "\n",
      "    def forward(self, x__1):\n",
      "        _conv_bn_relu = self._conv_bn_relu(x__1)\n",
      "        return _conv_bn_relu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import unittest\n",
    "from typing import (Dict)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii.codegen import model_to_pytorch_script\n",
    "from nni.retiarii.utils import original_state_dict_hooks\n",
    "from nni.retiarii.converter.graph_gen import convert_to_graph, GraphConverterWithShape\n",
    "\n",
    "class ConvertMixin:\n",
    "    @staticmethod\n",
    "    def _convert_model(model, input):\n",
    "        script_module = torch.jit.script(model)\n",
    "        model_ir = convert_to_graph(script_module, model)\n",
    "        return model_ir\n",
    "\n",
    "class TestModels(unittest.TestCase,ConvertMixin):\n",
    "\n",
    "    def run_test(self, model, input, check_value=True):\n",
    "        model_ir = self._convert_model(model, input)\n",
    "        model_code = model_to_pytorch_script(model_ir)\n",
    "        print(model_code)\n",
    "\n",
    "        exec_vars = {}\n",
    "        exec(model_code + '\\n\\nconverted_model = _model()', exec_vars)\n",
    "        converted_model = exec_vars['converted_model']\n",
    "\n",
    "        with original_state_dict_hooks(converted_model):\n",
    "            converted_model.load_state_dict(model.state_dict())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            expected_output = model.eval()(*input)\n",
    "            converted_output = converted_model.eval()(*input)\n",
    "        if check_value:\n",
    "            try:\n",
    "                self.assertEqual(len(converted_output), len(expected_output))\n",
    "                for a, b in zip(converted_output, expected_output):\n",
    "                    torch.eq(a, b)\n",
    "            except:\n",
    "                self.assertEqual(converted_output, expected_output)\n",
    "        return converted_model\n",
    "\n",
    "    def test_nested_modulelist(self):\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self, num_nodes, num_ops_per_node):\n",
    "                super().__init__()\n",
    "                self.ops = nn.ModuleList()\n",
    "                self.num_nodes = num_nodes\n",
    "                self.num_ops_per_node = num_ops_per_node\n",
    "                for _ in range(num_nodes):\n",
    "                    self.ops.append(nn.ModuleList([nn.Linear(16, 16) for __ in range(num_ops_per_node)]))\n",
    "\n",
    "            def forward(self, x):\n",
    "                state = x\n",
    "                for ops in self.ops:\n",
    "                    for op in ops:\n",
    "                        state = op(state)\n",
    "                return state\n",
    "\n",
    "        model = Net(4, 2)\n",
    "        x = torch.rand((16, 16), dtype=torch.float)\n",
    "        self.run_test(model, (x, ))\n",
    "\n",
    "    def test_append_input_tensor(self):\n",
    "        from typing import List\n",
    "\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self, num_nodes):\n",
    "                super().__init__()\n",
    "                self.ops = nn.ModuleList()\n",
    "                self.num_nodes = num_nodes\n",
    "                for _ in range(num_nodes):\n",
    "                    self.ops.append(nn.Linear(16, 16))\n",
    "\n",
    "            def forward(self, x: List[torch.Tensor]):\n",
    "                state = x\n",
    "                for ops in self.ops:\n",
    "                    state.append(ops(state[-1]))\n",
    "                return state[-1]\n",
    "\n",
    "        model = Net(4)\n",
    "        x = torch.rand((1, 16), dtype=torch.float)\n",
    "        self.run_test(model, ([x], ))\n",
    "\n",
    "    def test_channels_shuffle(self):\n",
    "        class Net(nn.Module):\n",
    "            def forward(self, x):\n",
    "                bs, num_channels, height, width = x.size()\n",
    "                x = x.reshape(bs * num_channels // 2, 2, height * width)\n",
    "                x = x.permute(1, 0, 2)\n",
    "                x = x.reshape(2, -1, num_channels // 2, height, width)\n",
    "                return x[0], x[1]\n",
    "\n",
    "        model = Net()\n",
    "        x = torch.rand((1, 64, 224, 224), dtype=torch.float)\n",
    "        self.run_test(model, (x, ))\n",
    "\n",
    "    def test_identity_node(self):\n",
    "        class Net(nn.Module):\n",
    "            def forward(self, x):\n",
    "                return x\n",
    "\n",
    "        model = Net()\n",
    "        x = torch.rand((1, 64, 224, 224), dtype=torch.float)\n",
    "        self.run_test(model, (x, ))\n",
    "\n",
    "    def test_nn_sequential_inherit(self):\n",
    "        class ConvBNReLU(nn.Sequential):\n",
    "            def __init__(self):\n",
    "                super().__init__(\n",
    "                    nn.Conv2d(3, 3, 1, 1, bias=False),\n",
    "                    nn.BatchNorm2d(3),\n",
    "                    nn.ReLU(inplace=False)\n",
    "                )\n",
    "\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.conv_bn_relu = ConvBNReLU()\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.conv_bn_relu(x)\n",
    "\n",
    "        model = Net()\n",
    "        x = torch.rand((1, 3, 224, 224), dtype=torch.float)\n",
    "        self.run_test(model, (x, ))\n",
    "\n",
    "test_models = TestModels()\n",
    "test_models.test_nn_sequential_inherit()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "849bd15258cbc1fdb3dc8c930a1445a9f672620f82bbd55fbc814541035aa795"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
