{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([ 0.6682, -1.4162, -2.7463,  1.8377, -1.8727, -1.7920, -1.0083,  1.0476,\n",
      "        -2.7022, -0.4607], grad_fn=<AddBackward0>)\n",
      "graph(%self : __torch__.SimpleNet,\n",
      "      %x.1 : Tensor):\n",
      "  %linear1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%self)\n",
      "  %6 : Function = prim::Constant[name=\"linear\"]()\n",
      "  %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%linear1)\n",
      "  %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%linear1)\n",
      "  %x.5 : Tensor = aten::linear(%x.1, %weight.1, %bias.1) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "  %linear2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%self)\n",
      "  %10 : Function = prim::Constant[name=\"linear\"]()\n",
      "  %weight : Tensor = prim::GetAttr[name=\"weight\"](%linear2)\n",
      "  %bias : Tensor = prim::GetAttr[name=\"bias\"](%linear2)\n",
      "  %x.9 : Tensor = aten::linear(%x.5, %weight, %bias) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "  return (%x.9)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import brt\n",
    "import brt.nn as nn\n",
    "import torch\n",
    "from brt.prim import is_netlet\n",
    "# @basic_unit\n",
    "@brt.netlet\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(10, 10)\n",
    "        self.linear2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "simple_net = SimpleNet()\n",
    "print(is_netlet(simple_net))\n",
    "simple_net.forward = simple_net.pt_forward\n",
    "\n",
    "x = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "x = simple_net(x)\n",
    "print(x)\n",
    "script_simple_net = torch.jit.script(simple_net)\n",
    "simple_net_inlined_graph = script_simple_net.inlined_graph\n",
    "print(simple_net_inlined_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\"))\n",
      "Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\"))\n",
      "Node(id=2, name=_model__linear1, python_name=linear1, label=None, operation=ModuleOperator(type=\"__torch__.torch.nn.modules.linear.Linear\", in_features=10, out_features=10))\n",
      "Node(id=4, name=_model__linear2, python_name=linear2, label=None, operation=ModuleOperator(type=\"__torch__.torch.nn.modules.linear.Linear\", in_features=10, out_features=10))\n",
      "-----------------\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "\n",
      "import brt.nn\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class _model(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self._linear1 = torch.nn.modules.linear.Linear(in_features=10, out_features=10)\n",
      "        self._linear2 = torch.nn.modules.linear.Linear(in_features=10, out_features=10)\n",
      "        self._mapping_ = {'_linear1': 'linear1', '_linear2': 'linear2'}\n",
      "\n",
      "    def forward(self, x__1):\n",
      "        _linear1 = self._linear1(x__1)\n",
      "        _linear2 = self._linear2(_linear1)\n",
      "        return _linear2\n"
     ]
    }
   ],
   "source": [
    "from brt.graphgen import convert_to_graph\n",
    "from brt.codegen import model_to_pytorch_script\n",
    "model_ir = convert_to_graph(script_simple_net, simple_net)\n",
    "\n",
    "for node in model_ir.get_nodes():\n",
    "    print(node)\n",
    "\n",
    "print(\"-----------------\")\n",
    "\n",
    "for cell_node in model_ir.get_cell_nodes():\n",
    "    print(cell_node)\n",
    "\n",
    "model_code = model_to_pytorch_script(model_ir)\n",
    "print(model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.4458,  2.5542, -0.3188, -2.9574,  4.2428,  2.7199, -2.5572,  0.0227,\n",
      "         -6.4788,  0.2923]], grad_fn=<AddmmBackward0>), tensor([[-4.3528, -2.3810,  1.5321,  2.8667,  4.0990, -1.4264,  9.8560, -1.3717,\n",
      "         -3.5174, -0.0418]], grad_fn=<AddmmBackward0>)]\n",
      "(tensor([[-0.4458,  2.5542, -0.3188, -2.9574,  4.2428,  2.7199, -2.5572,  0.0227,\n",
      "         -6.4788,  0.2923]], grad_fn=<AddmmBackward0>), tensor([[-4.3528, -2.3810,  1.5321,  2.8667,  4.0990, -1.4264,  9.8560, -1.3717,\n",
      "         -3.5174, -0.0418]], grad_fn=<AddmmBackward0>))\n",
      "graph(%self : __torch__.Model,\n",
      "      %x.1 : Tensor):\n",
      "  %moe_model : __torch__.MoEModel = prim::GetAttr[name=\"moe_model\"](%self)\n",
      "  %4 : int = prim::Constant[value=0]() # /tmp/ipykernel_2957284/4277649058.py:18:41\n",
      "  %5 : int = prim::Constant[value=1]() # /tmp/ipykernel_2957284/4277649058.py:19:41\n",
      "  %6 : Function = prim::Constant[name=\"linear\"]()\n",
      "  %moe : __torch__.MoE = prim::GetAttr[name=\"moe\"](%moe_model)\n",
      "  %scatter_router : __torch__.brt.router.scatter_router.RandomScatterRouter = prim::GetAttr[name=\"scatter_router\"](%moe)\n",
      "  %9 : (Tensor[], Tensor[], Tensor) = ^forward()(%scatter_router, %x.1) # /tmp/ipykernel_2957284/4277649058.py:17:55\n",
      "  %route_results.1 : Tensor[], %reverse_indice.1 : Tensor[], %reverse_shape.1 : Tensor = prim::TupleUnpack(%9)\n",
      "  %expert1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"expert1\"](%moe)\n",
      "  %14 : Tensor = aten::__getitem__(%route_results.1, %4) # /tmp/ipykernel_2957284/4277649058.py:18:27\n",
      "  %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%expert1)\n",
      "  %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%expert1)\n",
      "  %x_0.1 : Tensor = aten::linear(%14, %weight.1, %bias.1) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "  %expert2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"expert2\"](%moe)\n",
      "  %19 : Tensor = aten::__getitem__(%route_results.1, %5) # /tmp/ipykernel_2957284/4277649058.py:19:27\n",
      "  %weight : Tensor = prim::GetAttr[name=\"weight\"](%expert2)\n",
      "  %bias : Tensor = prim::GetAttr[name=\"bias\"](%expert2)\n",
      "  %x_1.1 : Tensor = aten::linear(%19, %weight, %bias) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "  %gather_router : __torch__.brt.router.gather_router.RandomGatherRouter = prim::GetAttr[name=\"gather_router\"](%moe)\n",
      "  %24 : Tensor[] = prim::ListConstruct(%x_0.1, %x_1.1)\n",
      "  %x : Tensor = ^forward()(%gather_router, %24, %reverse_indice.1, %reverse_shape.1) # /tmp/ipykernel_2957284/4277649058.py:20:12\n",
      "  %26 : (Tensor, Tensor) = prim::TupleConstruct(%x_0.1, %x_1.1)\n",
      "  return (%26)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import brt\n",
    "import brt.nn as nn\n",
    "from brt.router import RandomScatterRouter, RandomGatherRouter\n",
    "\n",
    "\n",
    "@brt.netlet\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scatter_router = RandomScatterRouter(route_num=2)\n",
    "        self.expert1 = nn.Linear(10, 10)\n",
    "        self.expert2 = nn.Linear(10, 10)\n",
    "        self.gather_router = RandomGatherRouter(route_num=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        route_results, reverse_indice, reverse_shape = self.scatter_router(x)\n",
    "        x_0 = self.expert1(route_results[0])\n",
    "        x_1 = self.expert2(route_results[1])\n",
    "        x = self.gather_router([x_0, x_1], reverse_indice, reverse_shape)\n",
    "        return x_0, x_1\n",
    "\n",
    "\n",
    "@brt.netlet\n",
    "class MoEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.moe = MoE()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.moe(x)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.moe_model = MoEModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.moe_model(x)\n",
    "\n",
    "\n",
    "moe_model = Model()\n",
    "\n",
    "x = torch.Tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "# model.cuda()\n",
    "y = 10\n",
    "z = moe_model(x)\n",
    "print(z)\n",
    "\n",
    "\n",
    "# model.brt_script(True)\n",
    "script_moe_model = torch.jit.script(moe_model)\n",
    "print(script_moe_model.inlined_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\"))\n",
      "Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\"))\n",
      "Node(id=3, name=_model__moe_model__moe__Constant3, python_name=None, label=None, operation=PrimConstant(type=\"prim::Constant\", type='int', value=0))\n",
      "Node(id=4, name=_model__moe_model__moe__Constant4, python_name=None, label=None, operation=PrimConstant(type=\"prim::Constant\", type='int', value=1))\n",
      "Node(id=5, name=_model__moe_model__moe__Attr5, python_name=None, label=None, operation=PrimGetAttr(type=\"prim::GetAttr\", name='scatter_router', input='self', value=None))\n",
      "Node(id=6, name=_model__moe_model__moe__prim__PythonOp6, python_name=None, label=None, operation=PyTorchOperation(type=\"prim::PythonOp\"))\n",
      "Node(id=7, name=_model__moe_model__moe__TupleUnpack7, python_name=None, label=None, operation=PrimTupleUnpack(type=\"prim::TupleUnpack\"))\n",
      "Node(id=9, name=_model__moe_model__moe__aten____getitem__9, python_name=moe_model.moe.__getitem__, label=None, operation=AtenGetitem(type=\"aten::__getitem__\"))\n",
      "Node(id=10, name=_model__moe_model__moe__expert1, python_name=moe_model.moe.expert1, label=None, operation=ModuleOperator(type=\"__torch__.torch.nn.modules.linear.Linear\", in_features=10, out_features=10))\n",
      "Node(id=12, name=_model__moe_model__moe__aten____getitem__11, python_name=moe_model.moe.__getitem__, label=None, operation=AtenGetitem(type=\"aten::__getitem__\"))\n",
      "Node(id=13, name=_model__moe_model__moe__expert2, python_name=moe_model.moe.expert2, label=None, operation=ModuleOperator(type=\"__torch__.torch.nn.modules.linear.Linear\", in_features=10, out_features=10))\n",
      "Node(id=14, name=_model__moe_model__moe__Attr12, python_name=None, label=None, operation=PrimGetAttr(type=\"prim::GetAttr\", name='gather_router', input='self', value=None))\n",
      "Node(id=15, name=_model__moe_model__moe__ListConstruct13, python_name=None, label=None, operation=PrimListConstruct(type=\"prim::ListConstruct\"))\n",
      "Node(id=16, name=_model__moe_model__moe__prim__PythonOp14, python_name=None, label=None, operation=PyTorchOperation(type=\"prim::PythonOp\"))\n",
      "Node(id=17, name=_model__moe_model__moe__TupleConstruct15, python_name=None, label=None, operation=PrimTupleConstruct(type=\"prim::TupleConstruct\"))\n",
      "Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\"))\n",
      "Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\"))\n",
      "Node(id=18, name=_model__moe_model__moe, python_name=moe_model.moe, label=None, operation=Cell(type=\"_cell\"))\n",
      "Node(id=-1, name=_inputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_inputs\"))\n",
      "Node(id=-2, name=_outputs, python_name=None, label=None, operation=_IOPseudoOperation(type=\"_outputs\"))\n",
      "Node(id=19, name=_model__moe_model, python_name=moe_model, label=None, operation=Cell(type=\"_cell\"))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "unsupported operation type: prim::PythonOp ? None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2886866/715317280.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_pytorch_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/codegen/pytorch.py\u001b[0m in \u001b[0;36mmodel_to_pytorch_script\u001b[0;34m(model, placement)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtotal_pkgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mimport_pkgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_to_pytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtotal_pkgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_pkgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/codegen/pytorch.py\u001b[0m in \u001b[0;36mgraph_to_pytorch_model\u001b[0;34m(graph_name, graph, placement)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'shared'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0msubmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_variable_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0medge_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_forward_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/brainstorm_project/nni/nni/retiarii/operation.py\u001b[0m in \u001b[0;36mto_forward_code\u001b[0;34m(self, field, output, inputs, inputs_value)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not supposed to have aten::slice operation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'unsupported operation type: {self.type} ? {self._to_class_name()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unsupported operation type: prim::PythonOp ? None"
     ]
    }
   ],
   "source": [
    "from nni.retiarii.converter import convert_to_graph\n",
    "from nni.retiarii.codegen import model_to_pytorch_script\n",
    "model_ir = convert_to_graph(script_moe_model, moe_model)\n",
    "\n",
    "for node in model_ir.get_nodes():\n",
    "    print(node)\n",
    "\n",
    "model_code = model_to_pytorch_script(model_ir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, use_memory_efficient):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.use_memory_efficient = use_memory_efficient\n",
    "\n",
    "    @torch.jit.ignore(drop=True)\n",
    "    def memory_efficient(self, x):\n",
    "        import pdb\n",
    "\n",
    "        pdb.set_trace()\n",
    "        return x + 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use not-yet-scriptable memory efficient mode\n",
    "        if self.use_memory_efficient:\n",
    "            return self.memory_efficient(x)\n",
    "        else:\n",
    "            return x + 10\n",
    "\n",
    "\n",
    "m = torch.jit.script(MyModule(use_memory_efficient=False))\n",
    "# m.save(\"m.pt\")\n",
    "\n",
    "m = torch.jit.script(MyModule(use_memory_efficient=True))\n",
    "# exception raised\n",
    "print(m.inlined_graph)\n",
    "# m.save(\"m.pt\")\n",
    "# m(torch.rand(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6597,  1.9257, -1.5097, -4.6707, -0.4496,  3.1321,  1.4132,  1.1851,\n",
      "         0.9164,  0.7567], grad_fn=<AddBackward0>)\n",
      "tensor([-1.3143, -1.6946, -0.8486,  0.4667,  0.3905, -0.5602,  0.1592, -0.5632,\n",
      "         1.1540, -1.0938], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import brt.nn as nn\n",
    "import torch\n",
    "from brt import netlet, top_graph\n",
    "from brt.prim import unwrap_netlet, unwrap_redundant_netlet\n",
    "\n",
    "\n",
    "@top_graph\n",
    "@netlet\n",
    "class RedundantModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "redundant_model = RedundantModel()\n",
    "x = torch.Tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "x = redundant_model(x)\n",
    "print(x)\n",
    "\n",
    "# assert redundant_model._netlet_tag == True, \"netlet_tag is not set\"\n",
    "# assert redundant_model._top_graph == True, \"top_graph is not set\"\n",
    "\n",
    "redundant_model = unwrap_redundant_netlet(redundant_model)\n",
    "x = redundant_model(x)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "\n",
      "import nni.retiarii.nn.pytorch\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2894864/2141977247.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0mtest_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0mtest_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_nn_sequential_inherit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2894864/2141977247.py\u001b[0m in \u001b[0;36mtest_nn_sequential_inherit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2894864/2141977247.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(self, model, input, check_value)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mexec_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_code\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\nconverted_model = _model()\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mconverted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexec_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"converted_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_model' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import unittest\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii.codegen import model_to_pytorch_script\n",
    "from nni.retiarii.utils import original_state_dict_hooks\n",
    "from nni.retiarii.converter.graph_gen import convert_to_graph, GraphConverterWithShape\n",
    "from nni.retiarii.serializer import basic_unit\n",
    "\n",
    "class ConvertMixin:\n",
    "    @staticmethod\n",
    "    def _convert_model(model, input):\n",
    "        script_module = torch.jit.script(model)\n",
    "        model_ir = convert_to_graph(script_module, model)\n",
    "        return model_ir\n",
    "\n",
    "\n",
    "class TestModels(unittest.TestCase, ConvertMixin):\n",
    "    def run_test(self, model, input, check_value=True):\n",
    "        model_ir = self._convert_model(model, input)\n",
    "        model_code = model_to_pytorch_script(model_ir)\n",
    "        print(model_code)\n",
    "\n",
    "        exec_vars = {}\n",
    "        exec(model_code + \"\\n\\nconverted_model = _model()\", exec_vars)\n",
    "        converted_model = exec_vars[\"converted_model\"]\n",
    "\n",
    "        with original_state_dict_hooks(converted_model):\n",
    "            converted_model.load_state_dict(model.state_dict())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            expected_output = model.eval()(*input)\n",
    "            converted_output = converted_model.eval()(*input)\n",
    "        if check_value:\n",
    "            try:\n",
    "                self.assertEqual(len(converted_output), len(expected_output))\n",
    "                for a, b in zip(converted_output, expected_output):\n",
    "                    torch.eq(a, b)\n",
    "            except:\n",
    "                self.assertEqual(converted_output, expected_output)\n",
    "        return converted_model\n",
    "\n",
    "    def test_nested_modulelist(self):\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self, num_nodes, num_ops_per_node):\n",
    "                super().__init__()\n",
    "                self.ops = nn.ModuleList()\n",
    "                self.num_nodes = num_nodes\n",
    "                self.num_ops_per_node = num_ops_per_node\n",
    "                for _ in range(num_nodes):\n",
    "                    self.ops.append(\n",
    "                        nn.ModuleList(\n",
    "                            [nn.Linear(16, 16) for __ in range(num_ops_per_node)]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            def forward(self, x):\n",
    "                state = x\n",
    "                for ops in self.ops:\n",
    "                    for op in ops:\n",
    "                        state = op(state)\n",
    "                return state\n",
    "\n",
    "        model = Net(4, 2)\n",
    "        x = torch.rand((16, 16), dtype=torch.float)\n",
    "        self.run_test(model, (x,))\n",
    "\n",
    "    def test_append_input_tensor(self):\n",
    "        from typing import List\n",
    "\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self, num_nodes):\n",
    "                super().__init__()\n",
    "                self.ops = nn.ModuleList()\n",
    "                self.num_nodes = num_nodes\n",
    "                for _ in range(num_nodes):\n",
    "                    self.ops.append(nn.Linear(16, 16))\n",
    "\n",
    "            def forward(self, x: List[torch.Tensor]):\n",
    "                state = x\n",
    "                for ops in self.ops:\n",
    "                    state.append(ops(state[-1]))\n",
    "                return state[-1]\n",
    "\n",
    "        model = Net(4)\n",
    "        x = torch.rand((1, 16), dtype=torch.float)\n",
    "        self.run_test(model, ([x],))\n",
    "\n",
    "    def test_channels_shuffle(self):\n",
    "        class Net(nn.Module):\n",
    "            def forward(self, x):\n",
    "                bs, num_channels, height, width = x.size()\n",
    "                x = x.reshape(bs * num_channels // 2, 2, height * width)\n",
    "                x = x.permute(1, 0, 2)\n",
    "                x = x.reshape(2, -1, num_channels // 2, height, width)\n",
    "                return x[0], x[1]\n",
    "\n",
    "        model = Net()\n",
    "        x = torch.rand((1, 64, 224, 224), dtype=torch.float)\n",
    "        self.run_test(model, (x,))\n",
    "\n",
    "    def test_identity_node(self):\n",
    "        class Net(nn.Module):\n",
    "            def forward(self, x):\n",
    "                return x\n",
    "\n",
    "        model = Net()\n",
    "        x = torch.rand((1, 64, 224, 224), dtype=torch.float)\n",
    "        self.run_test(model, (x,))\n",
    "\n",
    "    def test_nn_sequential_inherit(self):\n",
    "        class ConvBNReLU(nn.Sequential):\n",
    "            def __init__(self):\n",
    "                super().__init__(\n",
    "                    nn.Conv2d(3, 3, 1, 1, bias=False),\n",
    "                    nn.BatchNorm2d(3),\n",
    "                    nn.ReLU(inplace=False),\n",
    "                )\n",
    "\n",
    "        # @basic_unit\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.conv_bn_relu = ConvBNReLU()\n",
    "\n",
    "            def forward(self, x):\n",
    "                return self.conv_bn_relu(x)\n",
    "\n",
    "        model = Net()\n",
    "        x = torch.rand((1, 3, 224, 224), dtype=torch.float)\n",
    "        self.run_test(model, (x,))\n",
    "\n",
    "\n",
    "test_models = TestModels()\n",
    "test_models.test_nn_sequential_inherit()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "849bd15258cbc1fdb3dc8c930a1445a9f672620f82bbd55fbc814541035aa795"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
