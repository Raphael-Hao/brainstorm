{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2486,  0.3125,  0.1019, -0.0980,  0.1306,  0.2705,  0.0085,  0.0107,\n",
      "         0.0762, -0.2261], grad_fn=<AddBackward0>)\n",
      "None\n",
      "graph(%self : __torch__.brt.graph.___torch_mangle_1.wrapper,\n",
      "      %x.1 : Tensor,\n",
      "      %y.1 : int):\n",
      "  %3 : bool = prim::Constant[value=1]() # /tmp/ipykernel_1007005/2018613437.py:14:8\n",
      "  %x : Tensor = prim::Loop(%y.1, %3, %x.1) # /tmp/ipykernel_1007005/2018613437.py:14:8\n",
      "    block0(%i : int, %x.17 : Tensor):\n",
      "      %linear1 : __torch__.brt.graph.wrapper = prim::GetAttr[name=\"linear1\"](%self)\n",
      "      %11 : Function = prim::Constant[name=\"linear\"]()\n",
      "      %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%linear1)\n",
      "      %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%linear1)\n",
      "      %x.5 : Tensor = aten::linear(%x.17, %weight.1, %bias.1) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      %linear2 : __torch__.brt.graph.wrapper = prim::GetAttr[name=\"linear2\"](%self)\n",
      "      %15 : Function = prim::Constant[name=\"linear\"]()\n",
      "      %weight : Tensor = prim::GetAttr[name=\"weight\"](%linear2)\n",
      "      %bias : Tensor = prim::GetAttr[name=\"bias\"](%linear2)\n",
      "      %x.11 : Tensor = aten::linear(%x.5, %weight, %bias) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      -> (%3, %x.11)\n",
      "  return (%x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import brt\n",
    "import brt.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "@brt.top_graph\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(10, 10)\n",
    "        self.linear2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x, y: int):\n",
    "        for i in range(y):\n",
    "            x = self.linear1(x)\n",
    "            x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "simple_net = SimpleNet()\n",
    "\n",
    "x = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "x = simple_net(x, 10)\n",
    "print(x)\n",
    "x = simple_net(None, 10)\n",
    "print(x)\n",
    "script_simple_net = torch.jit.script(simple_net)\n",
    "simple_net_inlined_graph = script_simple_net.inlined_graph\n",
    "print(simple_net_inlined_graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_simple_net.save(\"simple_net.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2073, -0.2659, -0.1750,  0.2358,  0.2630,  0.3643,  0.0676,  0.2210,\n",
      "         -0.2627,  0.1155],\n",
      "        [-0.0605, -0.3800,  0.0009, -0.0936, -0.1959,  0.1131, -0.3850, -0.0184,\n",
      "         -0.4683, -0.0590]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "graph(%self : __torch__.brt.graph.___torch_mangle_3.wrapper,\n",
      "      %x.1 : Tensor,\n",
      "      %y.1 : int):\n",
      "  %moe : __torch__.___torch_mangle_2.MoE = prim::GetAttr[name=\"moe\"](%self)\n",
      "  %5 : Function = prim::Constant[name=\"linear\"]()\n",
      "  %6 : int = prim::Constant[value=1]() # /tmp/ipykernel_1007005/1820598631.py:19:45\n",
      "  %7 : int = prim::Constant[value=0]() # /tmp/ipykernel_1007005/1820598631.py:18:45\n",
      "  %8 : bool = prim::Constant[value=1]() # /tmp/ipykernel_1007005/1820598631.py:16:8\n",
      "  %x : Tensor = prim::Loop(%y.1, %8, %x.1) # /tmp/ipykernel_1007005/1820598631.py:16:8\n",
      "    block0(%i : int, %x.11 : Tensor):\n",
      "      %scatter_router : __torch__.brt.router.scatter_router.RandomScatterRouter = prim::GetAttr[name=\"scatter_router\"](%moe)\n",
      "      %13 : (Tensor, Tensor, Tensor) = ^forward()(%scatter_router, %x.11) # /tmp/ipykernel_1007005/1820598631.py:17:58\n",
      "      %route_results.1 : Tensor, %reverse_indice.1 : Tensor, %origin_shape.1 : Tensor = prim::TupleUnpack(%13)\n",
      "      %expert1 : __torch__.brt.graph.wrapper = prim::GetAttr[name=\"expert1\"](%moe)\n",
      "      %18 : Tensor = aten::select(%route_results.1, %7, %7) # /tmp/ipykernel_1007005/1820598631.py:18:31\n",
      "      %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%expert1)\n",
      "      %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%expert1)\n",
      "      %x_0.1 : Tensor = aten::linear(%18, %weight.1, %bias.1) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      %expert2 : __torch__.brt.graph.wrapper = prim::GetAttr[name=\"expert2\"](%moe)\n",
      "      %23 : Tensor = aten::select(%route_results.1, %7, %6) # /tmp/ipykernel_1007005/1820598631.py:19:31\n",
      "      %weight : Tensor = prim::GetAttr[name=\"weight\"](%expert2)\n",
      "      %bias : Tensor = prim::GetAttr[name=\"bias\"](%expert2)\n",
      "      %x_1.1 : Tensor = aten::linear(%23, %weight, %bias) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      %gather_router : __torch__.brt.router.gather_router.RandomGatherRouter = prim::GetAttr[name=\"gather_router\"](%moe)\n",
      "      %x.5 : Tensor = ^forward()(%gather_router, %reverse_indice.1, %origin_shape.1, %x_0.1, %x_1.1) # /tmp/ipykernel_1007005/1820598631.py:20:16\n",
      "      -> (%8, %x.5)\n",
      "  return (%x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import brt\n",
    "import brt.nn as nn\n",
    "from brt.router import RandomScatterRouter, RandomGatherRouter\n",
    "\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scatter_router = RandomScatterRouter(route_num=2)\n",
    "        self.expert1 = nn.Linear(10, 10)\n",
    "        self.expert2 = nn.Linear(10, 10)\n",
    "        self.gather_router = RandomGatherRouter(route_num=2)\n",
    "\n",
    "    def forward(self, x, y: int):\n",
    "        for i in range(y):\n",
    "            route_results, reverse_indice, origin_shape = self.scatter_router(x)\n",
    "            x_0 = self.expert1(route_results[0])\n",
    "            x_1 = self.expert2(route_results[1])\n",
    "            x = self.gather_router(\n",
    "                reverse_indice,\n",
    "                origin_shape,\n",
    "                x_0,\n",
    "                x_1,\n",
    "            )\n",
    "        return x\n",
    "\n",
    "\n",
    "@brt.top_graph\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.moe = MoE()\n",
    "\n",
    "    def forward(self, x, y: int):\n",
    "        return self.moe(x, y)\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "x = torch.Tensor(\n",
    "    [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]\n",
    ").cuda()\n",
    "model.cuda()\n",
    "y=10\n",
    "z = model(x, y)\n",
    "print(z)\n",
    "\n",
    "\n",
    "# model.brt_script(True)\n",
    "script_model = torch.jit.script(model)\n",
    "print(script_model.inlined_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nCould not export Python function call 'forward'. Remove calls to Python functions before export. Did you forget to add @script or @script_method annotation? If this is a nn.ModuleList, add it to __constants__:\n  File \"/tmp/ipykernel_1007005/1820598631.py\", line 17\n    def forward(self, x, y: int):\n        for i in range(y):\n            route_results, reverse_indice, origin_shape = self.scatter_router(x)\n                                                          ~~~~~~~~~~~~~~~~~~~ <--- HERE\n            x_0 = self.expert1(route_results[0])\n            x_1 = self.expert2(route_results[1])\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1007005/2713941781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscript_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, f, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \"\"\"\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_save_for_lite_interpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nCould not export Python function call 'forward'. Remove calls to Python functions before export. Did you forget to add @script or @script_method annotation? If this is a nn.ModuleList, add it to __constants__:\n  File \"/tmp/ipykernel_1007005/1820598631.py\", line 17\n    def forward(self, x, y: int):\n        for i in range(y):\n            route_results, reverse_indice, origin_shape = self.scatter_router(x)\n                                                          ~~~~~~~~~~~~~~~~~~~ <--- HERE\n            x_0 = self.expert1(route_results[0])\n            x_1 = self.expert2(route_results[1])\n"
     ]
    }
   ],
   "source": [
    "script_model.save(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, use_memory_efficient):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.use_memory_efficient = use_memory_efficient\n",
    "\n",
    "    @torch.jit.ignore(drop=True)\n",
    "    def memory_efficient(self, x):\n",
    "        import pdb\n",
    "\n",
    "        pdb.set_trace()\n",
    "        return x + 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use not-yet-scriptable memory efficient mode\n",
    "        if self.use_memory_efficient:\n",
    "            return self.memory_efficient(x)\n",
    "        else:\n",
    "            return x + 10\n",
    "\n",
    "\n",
    "m = torch.jit.script(MyModule(use_memory_efficient=False))\n",
    "# m.save(\"m.pt\")\n",
    "\n",
    "m = torch.jit.script(MyModule(use_memory_efficient=True))\n",
    "# exception raised\n",
    "print(m.inlined_graph)\n",
    "# m.save(\"m.pt\")\n",
    "# m(torch.rand(100))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "849bd15258cbc1fdb3dc8c930a1445a9f672620f82bbd55fbc814541035aa795"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
