{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1035,  0.3010,  0.2266, -0.2274,  0.3631,  0.1613,  0.2359, -0.0746,\n",
      "        -0.0900,  0.0652], grad_fn=<AddBackward0>)\n",
      "graph(%self : __torch__.brt.netlet.___torch_mangle_0.wrapper,\n",
      "      %x.1 : Tensor,\n",
      "      %y.1 : int):\n",
      "  %3 : bool = prim::Constant[value=1]() # /tmp/ipykernel_1110553/4091440697.py:14:8\n",
      "  %x : Tensor = prim::Loop(%y.1, %3, %x.1) # /tmp/ipykernel_1110553/4091440697.py:14:8\n",
      "    block0(%i : int, %x.17 : Tensor):\n",
      "      %linear1 : __torch__.brt.netlet.wrapper = prim::GetAttr[name=\"linear1\"](%self)\n",
      "      %11 : Function = prim::Constant[name=\"linear\"]()\n",
      "      %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%linear1)\n",
      "      %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%linear1)\n",
      "      %x.5 : Tensor = aten::linear(%x.17, %weight.1, %bias.1) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      %linear2 : __torch__.brt.netlet.wrapper = prim::GetAttr[name=\"linear2\"](%self)\n",
      "      %15 : Function = prim::Constant[name=\"linear\"]()\n",
      "      %weight : Tensor = prim::GetAttr[name=\"weight\"](%linear2)\n",
      "      %bias : Tensor = prim::GetAttr[name=\"bias\"](%linear2)\n",
      "      %x.11 : Tensor = aten::linear(%x.5, %weight, %bias) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      -> (%3, %x.11)\n",
      "  return (%x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import brt\n",
    "import brt.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "@brt.netlet\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(10, 10)\n",
    "        self.linear2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x, y: int):\n",
    "        for i in range(y):\n",
    "            x = self.linear1(x)\n",
    "            x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "simple_net = SimpleNet()\n",
    "\n",
    "x = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "x = simple_net(x, 10)\n",
    "print(x)\n",
    "\n",
    "simple_net.brt(True)\n",
    "script_simple_net = torch.jit.script(simple_net)\n",
    "simple_net_inlined_graph = script_simple_net.inlined_graph\n",
    "print(simple_net_inlined_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])]\n",
      "[tensor([[ 3.5053e-02, -3.0767e+00, -4.2341e-03, -2.8722e+00, -3.7326e+00,\n",
      "          3.9108e+00,  1.0917e+00,  5.3074e+00, -1.0823e+00,  2.0326e+00]],\n",
      "       grad_fn=<StackBackward0>), tensor([[ 3.5053e-02, -3.0767e+00, -4.2341e-03, -2.8722e+00, -3.7326e+00,\n",
      "          3.9108e+00,  1.0917e+00,  5.3074e+00, -1.0823e+00,  2.0326e+00]],\n",
      "       grad_fn=<StackBackward0>)]\n",
      "[None, tensor([[-0.6160,  1.6336,  0.8787, -1.7561,  1.5403, -0.6676,  0.1043, -0.5224,\n",
      "         -1.5715, -2.3269],\n",
      "        [-3.3846, -3.6145,  2.3732, -0.7463,  0.9669, -1.4154, -0.4790, -2.5548,\n",
      "         -3.0576,  2.0615]], grad_fn=<StackBackward0>)]\n",
      "[tensor([[ 0.8302,  0.3068,  0.3192,  0.2066,  0.2634, -0.2640, -0.9765,  0.4962,\n",
      "          1.1794,  0.2318]], grad_fn=<StackBackward0>), tensor([[ 2.4163,  0.4960,  2.0154,  0.4898, -2.0935, -0.7519,  0.1408, -2.0699,\n",
      "          0.5020, -0.4846]], grad_fn=<StackBackward0>)]\n",
      "[None, tensor([[ 0.5010, -0.2812,  0.1752,  0.5245, -0.5496,  0.0510,  0.0105,  0.3275,\n",
      "         -0.1442, -0.1550],\n",
      "        [-0.9747, -0.4686, -0.5640,  0.9268,  0.3812,  0.4172,  0.0853,  0.4703,\n",
      "          0.3053,  0.0709]], grad_fn=<StackBackward0>)]\n",
      "[tensor([[ 0.6773,  0.3524, -0.4752, -0.9161, -0.2712,  0.1711,  0.5081, -0.1128,\n",
      "         -0.4596, -0.4460]], grad_fn=<StackBackward0>), tensor([[ 0.1225,  0.3287, -0.4307, -0.3281,  0.1259,  0.3172,  0.3052,  0.1221,\n",
      "         -0.3382, -0.3007]], grad_fn=<StackBackward0>)]\n",
      "[tensor([[-0.4480, -0.2987,  0.2391,  0.1232, -0.1531, -0.4111,  0.0352, -0.3707,\n",
      "         -0.0985, -0.1890]], grad_fn=<StackBackward0>), tensor([[ 0.1260,  0.3923, -0.3570, -0.2603,  0.2574,  0.0599,  0.1052,  0.2320,\n",
      "         -0.2054,  0.0995]], grad_fn=<StackBackward0>)]\n",
      "[tensor([[ 0.2685,  0.3585, -0.3440, -0.2256,  0.0515,  0.2574,  0.2503,  0.4295,\n",
      "         -0.1502,  0.1236]], grad_fn=<StackBackward0>), tensor([[-0.2542,  0.2243,  0.1663,  0.0933, -0.3086, -0.0034, -0.0133, -0.0294,\n",
      "          0.4728, -0.2593]], grad_fn=<StackBackward0>)]\n",
      "[None, tensor([[-0.3790, -0.2570,  0.2008,  0.2072, -0.0843, -0.4273, -0.0319, -0.2602,\n",
      "         -0.0779, -0.3080],\n",
      "        [ 0.2586,  0.1536, -0.4366, -0.4266,  0.0685,  0.1610,  0.3055,  0.3310,\n",
      "          0.0583, -0.4905]], grad_fn=<StackBackward0>)]\n",
      "[tensor([[ 0.4825,  0.2463, -0.3038, -0.3044, -0.0913,  0.0872,  0.3028,  0.0317,\n",
      "          0.0477, -0.4347]], grad_fn=<StackBackward0>), tensor([[ 0.0796,  0.3304, -0.4475, -0.4341,  0.3441,  0.0955,  0.1478,  0.3804,\n",
      "         -0.1261, -0.1733]], grad_fn=<StackBackward0>)]\n",
      "tensor([[-0.1792, -0.2239,  0.1631,  0.2934, -0.2885, -0.2210,  0.0063, -0.1319,\n",
      "          0.0208, -0.2380],\n",
      "        [ 0.2725,  0.3747, -0.3552, -0.3627,  0.1526,  0.1946,  0.1855,  0.4501,\n",
      "         -0.1054, -0.0071]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import brt\n",
    "import brt.nn as nn\n",
    "from brt.router import RandomScatterRouter, RandomGatherRouter\n",
    "\n",
    "\n",
    "@brt.netlet\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scatter_router = RandomScatterRouter(route_num=2)\n",
    "        self.expert1 = nn.Linear(10, 10)\n",
    "        self.expert2 = nn.Linear(10, 10)\n",
    "        self.gather_router = RandomGatherRouter(route_num=2)\n",
    "\n",
    "    def forward(self, x, y: int):\n",
    "        for i in range(y):\n",
    "            route_results, reverse_indice, origin_shape = self.scatter_router(x)\n",
    "            x_0 = self.expert1(route_results[0])\n",
    "            x_1 = self.expert2(route_results[1])\n",
    "            x = self.gather_router(reverse_indice, origin_shape, x_0, x_1)\n",
    "        return x\n",
    "\n",
    "\n",
    "moe = MoE()\n",
    "\n",
    "x = torch.Tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "y = 10\n",
    "z = moe(x, y)\n",
    "\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self : __torch__.brt.netlet.___torch_mangle_1.wrapper,\n",
      "      %x.1 : Tensor,\n",
      "      %y.1 : int):\n",
      "  %3 : bool = prim::Constant[value=1]() # /tmp/ipykernel_958749/1823930129.py:17:8\n",
      "  %4 : int = prim::Constant[value=0]() # /tmp/ipykernel_958749/1823930129.py:19:45\n",
      "  %5 : int = prim::Constant[value=1]() # /tmp/ipykernel_958749/1823930129.py:20:45\n",
      "  %x : Tensor = prim::Loop(%y.1, %3, %x.1) # /tmp/ipykernel_958749/1823930129.py:17:8\n",
      "    block0(%i : int, %x.11 : Tensor):\n",
      "      %scatter_router : __torch__.brt.router.scatter_router.RandomScatterRouter = prim::GetAttr[name=\"scatter_router\"](%self)\n",
      "      %10 : (Tensor, Tensor, Tensor) = ^forward()(%scatter_router, %x.11) # /tmp/ipykernel_958749/1823930129.py:18:58\n",
      "      %route_results.1 : Tensor, %reverse_indice.1 : Tensor, %origin_shape.1 : Tensor = prim::TupleUnpack(%10)\n",
      "      %expert1 : __torch__.brt.netlet.wrapper = prim::GetAttr[name=\"expert1\"](%self)\n",
      "      %15 : Tensor = aten::select(%route_results.1, %4, %4) # /tmp/ipykernel_958749/1823930129.py:19:31\n",
      "      %22 : Function = prim::Constant[name=\"linear\"]()\n",
      "      %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%expert1)\n",
      "      %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%expert1)\n",
      "      %x_0.1 : Tensor = aten::linear(%15, %weight.1, %bias.1) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      %expert2 : __torch__.brt.netlet.wrapper = prim::GetAttr[name=\"expert2\"](%self)\n",
      "      %18 : Tensor = aten::select(%route_results.1, %4, %5) # /tmp/ipykernel_958749/1823930129.py:20:31\n",
      "      %26 : Function = prim::Constant[name=\"linear\"]()\n",
      "      %weight : Tensor = prim::GetAttr[name=\"weight\"](%expert2)\n",
      "      %bias : Tensor = prim::GetAttr[name=\"bias\"](%expert2)\n",
      "      %x_1.1 : Tensor = aten::linear(%18, %weight, %bias) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      %gather_router : __torch__.brt.router.gather_router.RandomGatherRouter = prim::GetAttr[name=\"gather_router\"](%self)\n",
      "      %x.5 : Tensor = ^forward()(%gather_router, %reverse_indice.1, %origin_shape.1, %x_0.1, %x_1.1) # /tmp/ipykernel_958749/1823930129.py:21:16\n",
      "      -> (%3, %x.5)\n",
      "  return (%x)\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_reduction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_958749/4219150531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0m_reduction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_reduction'"
     ]
    }
   ],
   "source": [
    "moe.brt(True)\n",
    "script_moe = torch.jit.script(moe)\n",
    "\n",
    "print(script_moe.inlined_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self : __torch__.brt.netlet.___torch_mangle_1.wrapper,\n",
      "      %x.1 : Tensor,\n",
      "      %y.1 : int):\n",
      "  %3 : bool = prim::Constant[value=1]() # /tmp/ipykernel_2208925/1408058768.py:17:8\n",
      "  %4 : int = prim::Constant[value=0]() # /tmp/ipykernel_2208925/1408058768.py:19:45\n",
      "  %5 : int = prim::Constant[value=1]() # /tmp/ipykernel_2208925/1408058768.py:20:45\n",
      "  %x : Tensor = prim::Loop(%y.1, %3, %x.1) # /tmp/ipykernel_2208925/1408058768.py:17:8\n",
      "    block0(%i : int, %x.11 : Tensor):\n",
      "      %scatter_router : __torch__.brt.router.scatter_router.RandomScatterRouter = prim::GetAttr[name=\"scatter_router\"](%self)\n",
      "      %10 : (Tensor, Tensor, Tensor) = ^forward()(%scatter_router, %x.11) # /tmp/ipykernel_2208925/1408058768.py:18:58\n",
      "      %route_results.1 : Tensor, %reverse_indice.1 : Tensor, %origin_shape.1 : Tensor = prim::TupleUnpack(%10)\n",
      "      %expert1 : __torch__.brt.netlet.wrapper = prim::GetAttr[name=\"expert1\"](%self)\n",
      "      %15 : Tensor = aten::select(%route_results.1, %4, %4) # /tmp/ipykernel_2208925/1408058768.py:19:31\n",
      "      %22 : Function = prim::Constant[name=\"linear\"]()\n",
      "      %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%expert1)\n",
      "      %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%expert1)\n",
      "      %x_0.1 : Tensor = aten::linear(%15, %weight.1, %bias.1) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      %expert2 : __torch__.brt.netlet.wrapper = prim::GetAttr[name=\"expert2\"](%self)\n",
      "      %18 : Tensor = aten::select(%route_results.1, %4, %5) # /tmp/ipykernel_2208925/1408058768.py:20:31\n",
      "      %26 : Function = prim::Constant[name=\"linear\"]()\n",
      "      %weight : Tensor = prim::GetAttr[name=\"weight\"](%expert2)\n",
      "      %bias : Tensor = prim::GetAttr[name=\"bias\"](%expert2)\n",
      "      %x_1.1 : Tensor = aten::linear(%18, %weight, %bias) # /state/partition/whcui/tools/pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/torch/nn/functional.py:1848:11\n",
      "      %gather_router : __torch__.brt.router.gather_router.RandomGatherRouter = prim::GetAttr[name=\"gather_router\"](%self)\n",
      "      %x.5 : Tensor = ^forward()(%gather_router, %reverse_indice.1, %origin_shape.1, %x_0.1, %x_1.1) # /tmp/ipykernel_2208925/1408058768.py:21:16\n",
      "      -> (%3, %x.5)\n",
      "  return (%x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moe.brt(True)\n",
    "script_moe = torch.jit.script(moe)\n",
    "\n",
    "print(script_moe.inlined_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brt\n",
    "from brt.nn._reduction import *\n",
    "z = brt.nn._reduction\n",
    "import torch\n",
    "z = torch.nn._reduction\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "849bd15258cbc1fdb3dc8c930a1445a9f672620f82bbd55fbc814541035aa795"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
