{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/v-louyang/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Type, List, Union\n",
    "\n",
    "\n",
    "from brt.runtime.proto_tensor import (\n",
    "    collect_proto_attr_stack,\n",
    "    init_proto_tensor,\n",
    "    make_proto_tensor_from,\n",
    ")\n",
    "from brt.jit import make_jit_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusedLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        models: Union[List[nn.Module], List[nn.Sequential]],\n",
    "        input_shapes: List[torch.Size],\n",
    "        output_shapes: List[torch.Size],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        models = nn.ModuleList(models)\n",
    "        print(models)\n",
    "        self.num_submodels = len(models)\n",
    "        assert len(input_shapes) == self.num_submodels\n",
    "        assert len(output_shapes) == self.num_submodels\n",
    "        for i, model in enumerate(models):\n",
    "            for name, tensor in model.named_parameters(f\"m{i}\"):\n",
    "                self.register_parameter(name.replace(\".\", \"_\"), tensor)\n",
    "            for name, tensor in model.named_buffers(f\"m{i}\"):\n",
    "                self.register_buffer(name.replace(\".\", \"_\"), tensor)\n",
    "        self.input_shapes = input_shapes\n",
    "        self.output_shapes = output_shapes\n",
    "        sample_inputs = [torch.randn(shp).cuda() for shp in input_shapes]\n",
    "        self.fused_kernel = make_jit_kernel(\n",
    "            models, sample_inputs, opt_level=\"hetero_fuse\"\n",
    "        )\n",
    "        print([[n, t.shape] for n, t in self.named_parameters()])\n",
    "        self.ACTIVE_BLOCKS = [1] * self.num_submodels\n",
    "        # Conv2dBiasPReLU or Conv2dBias or ConvTranspose2dBias\n",
    "        if isinstance(models[0], nn.Sequential):\n",
    "            conv2d = models[0][0]\n",
    "            prelu = models[0][1]\n",
    "            if (\n",
    "                isinstance(conv2d, nn.Conv2d)\n",
    "                and conv2d.bias is not None\n",
    "                and isinstance(prelu, nn.PReLU)\n",
    "            ):\n",
    "                self.module_name = \"Conv2dBiasPReLU\"\n",
    "            else:\n",
    "                raise NotImplementedError(f\"{models}\")\n",
    "        elif isinstance(models[0], nn.Conv2d) and models[0].bias is not None:\n",
    "            self.module_name = \"Conv2dBias\"\n",
    "        elif isinstance(models[0], nn.ConvTranspose2d) and models[0].bias is not None:\n",
    "            self.module_name = \"ConvTranspose2dBias\"\n",
    "        else:\n",
    "            self.module_name = \"ERROR\"\n",
    "            raise NotImplementedError(f\"{models}\")\n",
    "\n",
    "        self.inputs_templete = {}\n",
    "        self.inputs_templete[\"forward\"] = []\n",
    "        if self.module_name == \"Conv2dBiasPReLU\":\n",
    "            for i in range(len(models)):\n",
    "                self.inputs_templete[\"forward\"].extend(\n",
    "                    [\n",
    "                        None,\n",
    "                        self.get_parameter(f\"m{i}_0_weight\"),\n",
    "                        None,\n",
    "                        self.get_parameter(f\"m{i}_0_bias\"),\n",
    "                        self.get_parameter(f\"m{i}_1_weight\"),\n",
    "                    ]\n",
    "                )\n",
    "            self.input_indices = [i * 5 for i in range(self.num_submodels)]\n",
    "            self.output_indices = [i * 5 + 2 for i in range(self.num_submodels)]\n",
    "        elif (\n",
    "            self.module_name == \"Conv2dBias\"\n",
    "            or self.module_name == \"ConvTranspose2dBias\"\n",
    "        ):\n",
    "            for i in range(len(models)):\n",
    "                self.inputs_templete[\"forward\"].extend(\n",
    "                    [\n",
    "                        None,\n",
    "                        self.get_parameter(f\"m{i}_weight\"),\n",
    "                        None,\n",
    "                        self.get_parameter(f\"m{i}_bias\"),\n",
    "                    ]\n",
    "                )\n",
    "            self.input_indices = [i * 4 for i in range(self.num_submodels)]\n",
    "            self.output_indices = [i * 4 + 2 for i in range(self.num_submodels)]\n",
    "        # elif self.module_name == \"ConvTranspose2dBias\":\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{self.module_name}\")\n",
    "        self.forward(sample_inputs)\n",
    "\n",
    "    def forward(self, inputs: List[torch.Tensor]):\n",
    "        for i in range(self.num_submodels):\n",
    "            self.inputs_templete[\"forward\"][self.input_indices[i]] = inputs[i]\n",
    "            self.inputs_templete[\"forward\"][self.output_indices[i]] = torch.empty(\n",
    "                self.output_shapes[i], device=\"cuda\"\n",
    "            )\n",
    "        self.fused_kernel(\n",
    "            *self.inputs_templete[\"forward\"], active_blocks=self.ACTIVE_BLOCKS\n",
    "        )\n",
    "        torch.cuda.synchronize()\n",
    "        outputs = [\n",
    "            self.inputs_templete[\"forward\"][index] for index in self.output_indices\n",
    "        ]\n",
    "        for i in range(self.num_submodels):\n",
    "            self.inputs_templete[\"forward\"][self.input_indices[i]] = None\n",
    "            self.inputs_templete[\"forward\"][self.output_indices[i]] = None\n",
    "        return outputs\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return self.module_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_SHAPE = [34, 3, 32, 32]\n",
    "OUT_SHAPE = [34, 16, 32, 32]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0.weight', '0.bias', '1.weight'])\n",
      "ModuleList(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "  )\n",
      ")\n",
      "[['m0_0_weight', torch.Size([16, 3, 5, 5])], ['m0_0_bias', torch.Size([16])], ['m0_1_weight', torch.Size([1])]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FusedLayer(Conv2dBiasPReLU)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "    nn.PReLU(),\n",
    ").cuda()\n",
    "\n",
    "pth_file_path = r\"/home/v-louyang/brainstorm_project/brainstorm/benchmark/classsr/experiments/pre_trained_models/ClassSR_FSRCNN.pth\"\n",
    "full_state_dict = torch.load(pth_file_path)\n",
    "# print(full_state_dict.keys())\n",
    "state_dict = {\n",
    "    key[15:]: full_state_dict[key]\n",
    "    for key in [\n",
    "        \"net1.head_conv.0.weight\",\n",
    "        \"net1.head_conv.0.bias\",\n",
    "        \"net1.head_conv.1.weight\",\n",
    "    ]\n",
    "}\n",
    "print(state_dict.keys())\n",
    "raw.load_state_dict(state_dict)\n",
    "raw.eval()\n",
    "\n",
    "fused = FusedLayer([raw], [IN_SHAPE], [OUT_SHAPE])\n",
    "fused.cuda()\n",
    "fused.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(IN_SHAPE).cuda()\n",
    "# print(f\"######## x: {x}\")\n",
    "\n",
    "y_raw = raw(x)\n",
    "# print(f\"######## raw: {y_raw}\")\n",
    "\n",
    "y_fused = fused([x])[0]\n",
    "# print(f\"######## fused: {y_fused}\")\n",
    "\n",
    "torch.allclose(y_fused, y_raw, rtol=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/v-louyang/brainstorm_project/brainstorm/benchmark/classsr/test_fuse.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmsra_a100/home/v-louyang/brainstorm_project/brainstorm/benchmark/classsr/test_fuse.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m fused_conv2d(\u001b[39m*\u001b[39mfused_inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmsra_a100/home/v-louyang/brainstorm_project/brainstorm/benchmark/classsr/test_fuse.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m fused_conv2d_out0 \u001b[39m=\u001b[39m fused_inputs[\u001b[39m2\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmsra_a100/home/v-louyang/brainstorm_project/brainstorm/benchmark/classsr/test_fuse.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mallclose(conv2d_out0, fused_conv2d_out0, rtol\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmsra_a100/home/v-louyang/brainstorm_project/brainstorm/benchmark/classsr/test_fuse.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(fused_conv2d_out0)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "        torch.randn(shp, device=\"cuda\")\n",
    "        for shp in [\n",
    "            [34, 12, 32, 32],\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "raw_nets = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=12, out_channels=och, kernel_size=3, stride=1, padding=1\n",
    "                ),\n",
    "                nn.PReLU(),\n",
    "            ).cuda()\n",
    "            for och in [12]\n",
    "        ]).cuda()\n",
    "\n",
    "fused_conv2d = make_jit_kernel(\n",
    "    raw_nets[0],\n",
    "    inputs[0],\n",
    "    # opt_level=\"hetero_fuse\",\n",
    ")\n",
    "\n",
    "fused_inputs = [\n",
    "    inputs[0],\n",
    "    raw_nets[0][0].weight,\n",
    "    torch.empty([34, 12, 32, 32]).cuda(),\n",
    "    raw_nets[0][0].bias.expand(12),\n",
    "    raw_nets[0][1].weight.expand(12),\n",
    "]\n",
    "\n",
    "conv2d_out0 = raw_nets[0](inputs[0])\n",
    "\n",
    "fused_conv2d(*fused_inputs)\n",
    "\n",
    "fused_conv2d_out0 = fused_inputs[2]\n",
    "\n",
    "print(torch.allclose(conv2d_out0, fused_conv2d_out0, rtol=0.1))\n",
    "print(fused_conv2d_out0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = [\n",
    "#         torch.randn(shp, device=\"cuda\")\n",
    "#         for shp in [\n",
    "#             [34, 3, 32, 32],\n",
    "#             [38, 3, 32, 32],\n",
    "#             [29, 3, 32, 32],\n",
    "#         ]\n",
    "#     ]\n",
    "\n",
    "# raw_nets = nn.ModuleList([\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(\n",
    "#                     in_channels=3, out_channels=och, kernel_size=5, stride=1, padding=2\n",
    "#                 ),\n",
    "#                 nn.PReLU(),\n",
    "#             ).cuda()\n",
    "#             for och in [16, 36, 56]\n",
    "#         ]).cuda()\n",
    "\n",
    "# fused_conv2d = make_jit_kernel(\n",
    "#     raw_nets,\n",
    "#     inputs,\n",
    "#     # opt_level=\"hetero_fuse\",\n",
    "# )\n",
    "\n",
    "# fused_inputs = [\n",
    "#     inputs[0],\n",
    "#     raw_nets[0][0].weight,\n",
    "#     torch.empty([34, 16, 32, 32]).cuda(),\n",
    "#     raw_nets[0][0].bias,\n",
    "#     raw_nets[0][1].weight,\n",
    "#     inputs[1],\n",
    "#     raw_nets[1][0].weight,\n",
    "#     torch.empty([38, 36, 32, 32]).cuda(),\n",
    "#     raw_nets[1][0].bias,\n",
    "#     raw_nets[1][1].weight,\n",
    "#     inputs[2],\n",
    "#     raw_nets[2][0].weight,\n",
    "#     torch.empty([29, 56, 32, 32]).cuda(),\n",
    "#     raw_nets[2][0].bias,\n",
    "#     raw_nets[2][1].weight,\n",
    "# ]\n",
    "\n",
    "# conv2d_out0 = raw_nets[0](inputs[0])\n",
    "# conv2d_out1 = raw_nets[1](inputs[1])\n",
    "# conv2d_out2 = raw_nets[2](inputs[2])\n",
    "\n",
    "# fused_conv2d(*fused_inputs, active_blocks=[1, 1, 1])\n",
    "\n",
    "# fused_conv2d_out0 = fused_inputs[2]\n",
    "# fused_conv2d_out1 = fused_inputs[7]\n",
    "# fused_conv2d_out2 = fused_inputs[12]\n",
    "\n",
    "# # print(fused_conv2d_out0)\n",
    "# print(torch.allclose(conv2d_out0, fused_conv2d_out0, rtol=0.1))\n",
    "# print(torch.allclose(conv2d_out1, fused_conv2d_out1, rtol=0.1))\n",
    "# print(torch.allclose(conv2d_out2, fused_conv2d_out2, rtol=0.1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ada0f2bafc207a9420389a0d15036c00ed757384986ead74c3b832cdd2f7c4ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
