{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.benchmark import Timer\n",
    "\n",
    "from brt.jit import make_jit_kernel\n",
    "\n",
    "from archs.fuse import TunedKernel, FusedLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "import more_itertools as mit\n",
    "from more_itertools import set_partitions\n",
    "\n",
    "jit_kernel_info = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{((4,), (1,)): 169.04701478779316,\n",
      " ((4,), (2,)): 176.61810852587223,\n",
      " ((4,), (3,)): 185.1822016760707,\n",
      " ((4,), (4,)): 193.07979382574558,\n",
      " ((4,), (5,)): 194.45340149104595,\n",
      " ((6,), (1,)): 210.38518752902746,\n",
      " ((6,), (2,)): 237.27540392428637,\n",
      " ((6,), (3,)): 337.4476917088032,\n",
      " ((6,), (4,)): 261.84439193457365,\n",
      " ((6,), (5,)): 243.706488981843,\n",
      " ((7,), (1,)): 261.0732102766633,\n",
      " ((7,), (2,)): 437.7095028758049,\n",
      " ((7,), (3,)): 425.736210308969,\n",
      " ((7,), (4,)): 447.4033135920763,\n",
      " ((7,), (5,)): 453.0767910182476,\n",
      " ((8,), (1,)): 263.5668031871319,\n",
      " ((8,), (2,)): 270.4497193917632,\n",
      " ((8,), (3,)): 284.30260717868805,\n",
      " ((8,), (4,)): 287.6819111406803,\n",
      " ((8,), (5,)): 298.7565938383341,\n",
      " ((12,), (1,)): 334.4644093886018,\n",
      " ((12,), (2,)): 366.01140163838863,\n",
      " ((12,), (3,)): 385.5569055303931,\n",
      " ((12,), (4,)): 398.6133029684424,\n",
      " ((12,), (5,)): 396.01740427315235,\n",
      " ((27,), (1,)): 774.1475012153387,\n",
      " ((27,), (2,)): 726.6403874382377,\n",
      " ((27,), (3,)): 655.2041042596102,\n",
      " ((27,), (4,)): 715.6047970056534,\n",
      " ((27,), (5,)): 723.8913094624877}\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(36, 36, 3, padding=1).eval().cuda()\n",
    "subnet_bs = sorted(\n",
    "    [6, 7, 12, 27, 8, 8, 8, 12, 12, 4]\n",
    ")  # [4, 6, 7, 8, 8, 8, 12, 12, 12, 27]\n",
    "\n",
    "for bs in set(subnet_bs):\n",
    "    for rank in range(1, 6):\n",
    "        inout_shape = [bs, 36, 32, 32]\n",
    "        x = torch.empty(inout_shape, device=\"cuda\")\n",
    "        kernel = TunedKernel(conv2d, inout_shape, inout_shape, rank)\n",
    "        time = (\n",
    "            Timer(\n",
    "                f\"kernel(x)\",\n",
    "                setup=\"from __main__ import kernel, x; import torch; torch.cuda.synchronize();\",\n",
    "            )\n",
    "            .timeit(100)\n",
    "            .mean\n",
    "            * 10e6\n",
    "        )\n",
    "        jit_kernel_info[((bs,), (rank,))] = time\n",
    "\n",
    "pprint(jit_kernel_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Group & Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW\t (4,) (1,)\n",
      "379.432->349.132, -30.300, -7.986%, 1\n",
      "\tAPPEND\t (4, 6) (1, 1)\n",
      "610.205->700.643, 90.438, 14.821%, 3\n",
      "\tCLOSE\t (4, 6) (1, 1)\n",
      "\tNEW\t (7,) (1,)\n",
      "524.640->509.755, -14.885, -2.837%, 2\n",
      "\tAPPEND\t (7, 8) (1, 2)\n",
      "773.322->685.944, -87.378, -11.299%, 2\n",
      "\tAPPEND\t (7, 8, 8) (1, 2, 2)\n",
      "949.511->876.967, -72.544, -7.640%, 2\n",
      "\tAPPEND\t (7, 8, 8, 8) (1, 2, 2, 2)\n",
      "1211.431->1226.181, 14.750, 1.218%, 2\n",
      "\tCLOSE\t (7, 8, 8, 8) (1, 2, 2, 2)\n",
      "\tNEW\t (12,) (1,)\n",
      "668.929->642.889, -26.040, -3.893%, 3\n",
      "\tAPPEND\t (12, 12) (1, 3)\n",
      "977.353->879.911, -97.442, -9.970%, 3\n",
      "\tAPPEND\t (12, 12, 12) (1, 3, 3)\n",
      "1535.115->1549.141, 14.026, 0.914%, 4\n",
      "\tCLOSE\t (12, 12, 12) (1, 3, 3)\n",
      "\tNEW\t (27,) (1,)\n",
      "\tCLOSE\t (27,) (1,)\n",
      "[((4, 6), (1, 1)), ((7, 8, 8, 8), (1, 2, 2, 2)), ((12, 12, 12), (1, 3, 3)), ((27,), (1,))]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "greedy_partition = []\n",
    "while i < len(subnet_bs):\n",
    "    cur_subnet_bs = (subnet_bs[i],)\n",
    "    cur_ranks = (1,)\n",
    "    print(f\"\\tNEW\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "    i = i + 1\n",
    "\n",
    "    while i < len(subnet_bs):\n",
    "        cur_time = jit_kernel_info[(cur_subnet_bs, cur_ranks)]\n",
    "        new_subnet_bs = cur_subnet_bs + (subnet_bs[i],)\n",
    "        new_inout_shapes = [[bs, 36, 32, 32] for bs in new_subnet_bs]\n",
    "        new_x = [torch.empty(shp, device=\"cuda\") for shp in new_inout_shapes]\n",
    "        rank_times = []\n",
    "        for rank in range(1, 6):\n",
    "            new_ranks = cur_ranks + (rank,)\n",
    "            new_kernel_rank = FusedLayer(\n",
    "                [conv2d] * len(new_subnet_bs),\n",
    "                new_inout_shapes,\n",
    "                new_inout_shapes,\n",
    "                new_ranks,\n",
    "            )\n",
    "            new_time_rank = (\n",
    "                Timer(\n",
    "                    f\"new_kernel_rank(new_x)\",\n",
    "                    setup=\"from __main__ import new_kernel_rank, new_x; import torch; torch.cuda.synchronize();\",\n",
    "                )\n",
    "                .timeit(100)\n",
    "                .mean\n",
    "                * 10e6\n",
    "            )\n",
    "            jit_kernel_info[(new_subnet_bs, new_ranks)] = new_time_rank\n",
    "            rank_times.append((new_ranks, new_time_rank))\n",
    "        new_ranks, new_time = min(rank_times, key=lambda x: x[1])\n",
    "        old_time = (\n",
    "            jit_kernel_info[(cur_subnet_bs, cur_ranks)]\n",
    "            + min([jit_kernel_info[((subnet_bs[i],), (rank,))] for rank in range(1, 6)])\n",
    "        )\n",
    "        print(\n",
    "            f\"{old_time:.3f}->{new_time:.3f}, {new_time-old_time:.3f}, {100 * (new_time/old_time-1):.3f}%, {new_ranks[-1]}\"\n",
    "        )\n",
    "        if new_time < old_time:\n",
    "            cur_subnet_bs = new_subnet_bs\n",
    "            cur_ranks = new_ranks\n",
    "            print(f\"\\tAPPEND\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "        else:\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "    print(f\"\\tCLOSE\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "    greedy_partition.append((cur_subnet_bs, cur_ranks))\n",
    "\n",
    "print(greedy_partition)\n",
    "# [[4, 6], [7], [8, 8, 8, 12, 12, 12], [27]]\n",
    "# [((4, 6), (1, 1)), ((7, 8, 8, 8), (1, 2, 2, 2)), ((12, 12, 12, 27), (1, 3, 3, 4))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3208.7465515360236\n",
      "2880.1569249480963\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([jit_kernel_info[((bs, ), (1, ))] for bs in subnet_bs])}\")\n",
    "print(f\"{sum([jit_kernel_info[info] for info in greedy_partition])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Group (Rank = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW\t (4,) (1,)\n",
      "376.892->348.704, -28.187, -7.479%, 1\n",
      "\tAPPEND\t (4, 6) (1, 1)\n",
      "609.790->845.561, 235.771, 38.664%, 1\n",
      "\tCLOSE\t (4, 6) (1, 1)\n",
      "\tNEW\t (7,) (1,)\n",
      "524.485->713.922, 189.437, 36.119%, 1\n",
      "\tCLOSE\t (7,) (1,)\n",
      "\tNEW\t (8,) (1,)\n",
      "526.800->465.021, -61.779, -11.727%, 1\n",
      "\tAPPEND\t (8, 8) (1, 1)\n",
      "728.421->686.387, -42.033, -5.770%, 1\n",
      "\tAPPEND\t (8, 8, 8) (1, 1, 1)\n",
      "1020.591->997.386, -23.205, -2.274%, 1\n",
      "\tAPPEND\t (8, 8, 8, 12) (1, 1, 1, 1)\n",
      "1331.590->1245.289, -86.301, -6.481%, 1\n",
      "\tAPPEND\t (8, 8, 8, 12, 12) (1, 1, 1, 1, 1)\n",
      "1579.493->1521.756, -57.737, -3.655%, 1\n",
      "\tAPPEND\t (8, 8, 8, 12, 12, 12) (1, 1, 1, 1, 1, 1)\n",
      "2295.558->2570.368, 274.809, 11.971%, 1\n",
      "\tCLOSE\t (8, 8, 8, 12, 12, 12) (1, 1, 1, 1, 1, 1)\n",
      "\tNEW\t (27,) (1,)\n",
      "\tCLOSE\t (27,) (1,)\n",
      "[((4, 6), (1, 1)), ((7,), (1,)), ((8, 8, 8, 12, 12, 12), (1, 1, 1, 1, 1, 1)), ((27,), (1,))]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "greedy_partition = []\n",
    "while i < len(subnet_bs):\n",
    "    cur_subnet_bs = (subnet_bs[i],)\n",
    "    cur_ranks = (1,)\n",
    "    print(f\"\\tNEW\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "    i = i + 1\n",
    "\n",
    "    while i < len(subnet_bs):\n",
    "        cur_time = jit_kernel_info[(cur_subnet_bs, cur_ranks)]\n",
    "        new_subnet_bs = cur_subnet_bs + (subnet_bs[i],)\n",
    "        new_inout_shapes = [[bs, 36, 32, 32] for bs in new_subnet_bs]\n",
    "        new_x = [torch.empty(shp, device=\"cuda\") for shp in new_inout_shapes]\n",
    "        rank_times = []\n",
    "        for rank in range(1, 2):\n",
    "            new_ranks = cur_ranks + (rank,)\n",
    "            new_kernel_rank = FusedLayer(\n",
    "                [conv2d] * len(new_subnet_bs),\n",
    "                new_inout_shapes,\n",
    "                new_inout_shapes,\n",
    "                new_ranks,\n",
    "            )\n",
    "            new_time_rank = (\n",
    "                Timer(\n",
    "                    f\"new_kernel_rank(new_x)\",\n",
    "                    setup=\"from __main__ import new_kernel_rank, new_x; import torch; torch.cuda.synchronize();\",\n",
    "                )\n",
    "                .timeit(100)\n",
    "                .mean\n",
    "                * 10e6\n",
    "            )\n",
    "            jit_kernel_info[(new_subnet_bs, new_ranks)] = new_time_rank\n",
    "            rank_times.append((new_ranks, new_time_rank))\n",
    "        new_ranks, new_time = min(rank_times, key=lambda x: x[1])\n",
    "        old_time = (\n",
    "            jit_kernel_info[(cur_subnet_bs, cur_ranks)]\n",
    "            + jit_kernel_info[((subnet_bs[i],), (1,))]\n",
    "        )\n",
    "        print(\n",
    "            f\"{old_time:.3f}->{new_time:.3f}, {new_time-old_time:.3f}, {100 * (new_time/old_time-1):.3f}%, {new_ranks[-1]}\"\n",
    "        )\n",
    "        if new_time < old_time:\n",
    "            cur_subnet_bs = new_subnet_bs\n",
    "            cur_ranks = new_ranks\n",
    "            print(f\"\\tAPPEND\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "        else:\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "    print(f\"\\tCLOSE\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "    greedy_partition.append((cur_subnet_bs, cur_ranks))\n",
    "\n",
    "print(greedy_partition)\n",
    "# [[4, 6], [7], [8, 8, 8, 12, 12, 12], [27]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3204.59078066051\n",
      "2905.34810628742\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([jit_kernel_info[((bs, ), (1, ))] for bs in subnet_bs])}\")\n",
    "print(f\"{sum([jit_kernel_info[info] for info in greedy_partition])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Rank (bs = 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# greedy_partition = []\n",
    "\n",
    "bs = 12\n",
    "num_models = 3\n",
    "\n",
    "new_subnet_bs = (bs,) * num_models\n",
    "\n",
    "for rank in range(1, 6):\n",
    "    new_ranks = (rank,) * num_models\n",
    "    print(f\"\\tNEW\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "    new_inout_shapes = [[bs, 36, 32, 32] for bs in new_subnet_bs]\n",
    "    new_kernel = FusedLayer(\n",
    "        [conv2d] * len(cur_subnet_bs),\n",
    "        new_inout_shapes,\n",
    "        new_inout_shapes,\n",
    "        new_ranks,\n",
    "    )\n",
    "    new_x = [torch.empty(shp, device=\"cuda\") for shp in new_inout_shapes]\n",
    "    new_time = (\n",
    "        Timer(\n",
    "            f\"new_kernel(new_x)\",\n",
    "            setup=\"from __main__ import new_kernel, new_x; import torch; torch.cuda.synchronize();\",\n",
    "        )\n",
    "        .timeit(100)\n",
    "        .mean\n",
    "        * 10e6\n",
    "    )\n",
    "    jit_kernel_info[(new_subnet_bs, new_ranks)] = new_time\n",
    "    old_time = jit_kernel_info[((bs,), (rank,))] * 3\n",
    "    print(\n",
    "        f\"{old_time:.3f}->{new_time:.3f}, {new_time-old_time:.3f}, {100 * (new_time/old_time-1):.3f}%, {new_ranks[-1]}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ada0f2bafc207a9420389a0d15036c00ed757384986ead74c3b832cdd2f7c4ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
