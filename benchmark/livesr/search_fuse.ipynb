{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/v-louyang/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.benchmark import Timer\n",
    "\n",
    "from brt.jit import make_jit_kernel\n",
    "\n",
    "from archs.fuse import TunedKernel, FusedLayer, set_objective_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<archs.fuse._ObjectiveFuncContext at 0x7f6dd08eb820>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "import more_itertools as mit\n",
    "from more_itertools import set_partitions\n",
    "\n",
    "jit_kernel_info = {}\n",
    "\n",
    "# set_objective_func(\"most_efficient\")\n",
    "set_objective_func(\"fastest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{((4,), (1,)): 76.71370112802833,\n",
      " ((4,), (2,)): 76.66559831704944,\n",
      " ((4,), (3,)): 76.72369829379022,\n",
      " ((4,), (4,)): 79.82650131452829,\n",
      " ((4,), (5,)): 78.78750038798898,\n",
      " ((6,), (1,)): 75.86000137962401,\n",
      " ((6,), (2,)): 76.4872005674988,\n",
      " ((6,), (3,)): 77.31569930911063,\n",
      " ((6,), (4,)): 75.33709867857397,\n",
      " ((6,), (5,)): 77.88689981680363,\n",
      " ((7,), (1,)): 79.88949946593493,\n",
      " ((7,), (2,)): 80.22819820325822,\n",
      " ((7,), (3,)): 77.30669749435037,\n",
      " ((7,), (4,)): 76.91799837630242,\n",
      " ((7,), (5,)): 83.97430065087974,\n",
      " ((8,), (1,)): 82.66670047305524,\n",
      " ((8,), (2,)): 76.09949971083552,\n",
      " ((8,), (3,)): 77.87380018271507,\n",
      " ((8,), (4,)): 76.3449992518872,\n",
      " ((8,), (5,)): 78.04009946994483,\n",
      " ((12,), (1,)): 78.08419759385288,\n",
      " ((12,), (2,)): 77.99899904057384,\n",
      " ((12,), (3,)): 80.83030115813017,\n",
      " ((12,), (4,)): 95.04499903414398,\n",
      " ((12,), (5,)): 102.02800040133297,\n",
      " ((27,), (1,)): 85.99010179750621,\n",
      " ((27,), (2,)): 93.129399465397,\n",
      " ((27,), (3,)): 112.57579899393022,\n",
      " ((27,), (4,)): 111.34850210510194,\n",
      " ((27,), (5,)): 114.96130027808249}\n"
     ]
    }
   ],
   "source": [
    "NUM_FEATURE = 8\n",
    "\n",
    "conv2d = nn.Conv2d(NUM_FEATURE, NUM_FEATURE, 3, padding=1).eval().cuda()\n",
    "subnet_bs = sorted(\n",
    "    [6, 7, 12, 27, 8, 8, 8, 12, 12, 4]\n",
    ")  # [4, 6, 7, 8, 8, 8, 12, 12, 12, 27]\n",
    "\n",
    "for bs in set(subnet_bs):\n",
    "    for rank in range(1, 6):\n",
    "        inout_shape = [bs, NUM_FEATURE, 32, 32]\n",
    "        x = torch.empty(inout_shape, device=\"cuda\")\n",
    "        kernel = TunedKernel(conv2d, inout_shape, inout_shape, rank)\n",
    "        time = (\n",
    "            Timer(\n",
    "                f\"kernel(x)\",\n",
    "                setup=\"from __main__ import kernel, x; import torch; torch.cuda.synchronize();\",\n",
    "            )\n",
    "            .timeit(100)\n",
    "            .mean\n",
    "            * 10e6\n",
    "        )\n",
    "        jit_kernel_info[((bs,), (rank,))] = time\n",
    "\n",
    "pprint(jit_kernel_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Group & Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW\t (4,) (1,)\n",
      "152.051->59.592, -92.458, -60.808%, 1\n",
      "\tAPPEND\t (4, 6) (1, 1)\n",
      "136.510->73.846, -62.664, -45.904%, 1\n",
      "\tAPPEND\t (4, 6, 7) (1, 1, 1)\n",
      "149.946->82.686, -67.260, -44.856%, 4\n",
      "\tAPPEND\t (4, 6, 7, 8) (1, 1, 1, 4)\n",
      "158.785->97.756, -61.029, -38.435%, 4\n",
      "\tAPPEND\t (4, 6, 7, 8, 8) (1, 1, 1, 4, 4)\n",
      "173.856->111.181, -62.674, -36.050%, 4\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8) (1, 1, 1, 4, 4, 4)\n",
      "189.180->142.784, -46.396, -24.525%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8, 12) (1, 1, 1, 4, 4, 4, 1)\n",
      "220.783->159.496, -61.288, -27.759%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8, 12, 12) (1, 1, 1, 4, 4, 4, 1, 1)\n",
      "237.495->191.513, -45.982, -19.361%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8, 12, 12, 12) (1, 1, 1, 4, 4, 4, 1, 1, 1)\n",
      "277.503->249.518, -27.985, -10.084%, 2\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8, 12, 12, 12, 27) (1, 1, 1, 4, 4, 4, 1, 1, 1, 2)\n",
      "\tCLOSE\t (4, 6, 7, 8, 8, 8, 12, 12, 12, 27) (1, 1, 1, 4, 4, 4, 1, 1, 1, 2)\n",
      "[((4, 6, 7, 8, 8, 8, 12, 12, 12, 27), (1, 1, 1, 4, 4, 4, 1, 1, 1, 2))]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "greedy_partition = []\n",
    "while i < len(subnet_bs):\n",
    "    cur_subnet_bs = (subnet_bs[i],)\n",
    "    cur_ranks = (1,)\n",
    "    # (cur_subnet_bs, cur_ranks), _ = min(\n",
    "    #     [x for x in jit_kernel_info.items() if x[0][0] == (subnet_bs[i],)],\n",
    "    #     key=lambda x: x[1],\n",
    "    # )\n",
    "    print(f\"\\tNEW\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "    i = i + 1\n",
    "\n",
    "    while i < len(subnet_bs):\n",
    "        cur_time = jit_kernel_info[(cur_subnet_bs, cur_ranks)]\n",
    "        new_subnet_bs = cur_subnet_bs + (subnet_bs[i],)\n",
    "        new_inout_shapes = [[bs, NUM_FEATURE, 32, 32] for bs in new_subnet_bs]\n",
    "        new_x = [torch.empty(shp, device=\"cuda\") for shp in new_inout_shapes]\n",
    "        rank_times = []\n",
    "        for rank in range(1, 6):\n",
    "            new_ranks = cur_ranks + (rank,)\n",
    "            new_kernel_rank = FusedLayer(\n",
    "                [conv2d] * len(new_subnet_bs),\n",
    "                new_inout_shapes,\n",
    "                new_inout_shapes,\n",
    "                new_ranks,\n",
    "            )\n",
    "            new_time_rank = (\n",
    "                Timer(\n",
    "                    f\"new_kernel_rank(new_x)\",\n",
    "                    setup=\"from __main__ import new_kernel_rank, new_x; import torch; torch.cuda.synchronize();\",\n",
    "                )\n",
    "                .timeit(100)\n",
    "                .mean\n",
    "                * 10e6\n",
    "            )\n",
    "            jit_kernel_info[(new_subnet_bs, new_ranks)] = new_time_rank\n",
    "            rank_times.append((new_ranks, new_time_rank))\n",
    "        new_ranks, new_time = min(rank_times, key=lambda x: x[1])\n",
    "        old_time = jit_kernel_info[(cur_subnet_bs, cur_ranks)] + min(\n",
    "            [jit_kernel_info[((subnet_bs[i],), (rank,))] for rank in range(1, 6)]\n",
    "        )\n",
    "        print(\n",
    "            f\"{old_time:.3f}->{new_time:.3f}, {new_time-old_time:.3f}, {100 * (new_time/old_time-1):.3f}%, {new_ranks[-1]}\"\n",
    "        )\n",
    "        if new_time < old_time:\n",
    "            cur_subnet_bs = new_subnet_bs\n",
    "            cur_ranks = new_ranks\n",
    "            print(f\"\\tAPPEND\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "        else:\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "    print(f\"\\tCLOSE\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "    greedy_partition.append((cur_subnet_bs, cur_ranks))\n",
    "\n",
    "print(greedy_partition)\n",
    "# [[4, 6], [7], [8, 8, 8, 12, 12, 12], [27]]\n",
    "# [((4, 6), (1, 1)), ((7, 8, 8, 8), (1, 2, 2, 2)), ((12, 12, 12, 27), (1, 3, 3, 4))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800.7059979718179\n",
      "249.5181019185111\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([jit_kernel_info[((bs, ), (1, ))] for bs in subnet_bs])}\")\n",
    "print(f\"{sum([jit_kernel_info[info] for info in greedy_partition])}\")\n",
    "# fastest\n",
    "## 2434.2245975276455\n",
    "## 2193.2725998340175\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Group (Rank = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW\t (4,) (1,)\n",
      "152.574->59.734, -92.840, -60.849%, 1\n",
      "\tAPPEND\t (4, 6) (1, 1)\n",
      "139.623->73.159, -66.464, -47.603%, 1\n",
      "\tAPPEND\t (4, 6, 7) (1, 1, 1)\n",
      "155.826->103.094, -52.732, -33.840%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8) (1, 1, 1, 1)\n",
      "185.761->103.390, -82.371, -44.343%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8, 8) (1, 1, 1, 1, 1)\n",
      "186.056->109.478, -76.578, -41.159%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8) (1, 1, 1, 1, 1, 1)\n",
      "187.562->136.492, -51.071, -27.229%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8, 12) (1, 1, 1, 1, 1, 1, 1)\n",
      "214.576->152.011, -62.565, -29.158%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8, 12, 12) (1, 1, 1, 1, 1, 1, 1, 1)\n",
      "230.095->181.061, -49.034, -21.310%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8, 12, 12, 12) (1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
      "267.051->231.056, -35.996, -13.479%, 1\n",
      "\tAPPEND\t (4, 6, 7, 8, 8, 8, 12, 12, 12, 27) (1, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
      "\tCLOSE\t (4, 6, 7, 8, 8, 8, 12, 12, 12, 27) (1, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
      "[((4, 6, 7, 8, 8, 8, 12, 12, 12, 27), (1, 1, 1, 1, 1, 1, 1, 1, 1, 1))]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "greedy_partition = []\n",
    "while i < len(subnet_bs):\n",
    "    cur_subnet_bs = (subnet_bs[i],)\n",
    "    cur_ranks = (1,)\n",
    "    print(f\"\\tNEW\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "    i = i + 1\n",
    "\n",
    "    while i < len(subnet_bs):\n",
    "        cur_time = jit_kernel_info[(cur_subnet_bs, cur_ranks)]\n",
    "        new_subnet_bs = cur_subnet_bs + (subnet_bs[i],)\n",
    "        new_inout_shapes = [[bs, NUM_FEATURE, 32, 32] for bs in new_subnet_bs]\n",
    "        new_x = [torch.empty(shp, device=\"cuda\") for shp in new_inout_shapes]\n",
    "        rank_times = []\n",
    "        for rank in range(1, 2):\n",
    "            new_ranks = cur_ranks + (rank,)\n",
    "            new_kernel_rank = FusedLayer(\n",
    "                [conv2d] * len(new_subnet_bs),\n",
    "                new_inout_shapes,\n",
    "                new_inout_shapes,\n",
    "                new_ranks,\n",
    "            )\n",
    "            new_time_rank = (\n",
    "                Timer(\n",
    "                    f\"new_kernel_rank(new_x)\",\n",
    "                    setup=\"from __main__ import new_kernel_rank, new_x; import torch; torch.cuda.synchronize();\",\n",
    "                )\n",
    "                .timeit(100)\n",
    "                .mean\n",
    "                * 10e6\n",
    "            )\n",
    "            jit_kernel_info[(new_subnet_bs, new_ranks)] = new_time_rank\n",
    "            rank_times.append((new_ranks, new_time_rank))\n",
    "        new_ranks, new_time = min(rank_times, key=lambda x: x[1])\n",
    "        old_time = (\n",
    "            jit_kernel_info[(cur_subnet_bs, cur_ranks)]\n",
    "            + jit_kernel_info[((subnet_bs[i],), (1,))]\n",
    "        )\n",
    "        print(\n",
    "            f\"{old_time:.3f}->{new_time:.3f}, {new_time-old_time:.3f}, {100 * (new_time/old_time-1):.3f}%, {new_ranks[-1]}\"\n",
    "        )\n",
    "        if new_time < old_time:\n",
    "            cur_subnet_bs = new_subnet_bs\n",
    "            cur_ranks = new_ranks\n",
    "            print(f\"\\tAPPEND\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "        else:\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "    print(f\"\\tCLOSE\\t {cur_subnet_bs} {cur_ranks}\")\n",
    "    greedy_partition.append((cur_subnet_bs, cur_ranks))\n",
    "\n",
    "print(greedy_partition)\n",
    "# [[4, 6], [7], [8, 8, 8, 12, 12, 12], [27]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800.7059979718179\n",
      "231.05560103431344\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([jit_kernel_info[((bs, ), (1, ))] for bs in subnet_bs])}\")\n",
    "print(f\"{sum([jit_kernel_info[info] for info in greedy_partition])}\")\n",
    "\n",
    "# fastest\n",
    "## 2434.2245975276455\n",
    "## 2235.7680994900875\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Rank (bs = 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== num_models = 2 ====================================\n",
      "152.199->67.498, -84.701, -55.651%, 1\n",
      "152.199->65.088, -87.111, -57.235%, 2\n",
      "152.199->69.417, -82.782, -54.391%, 3\n",
      "152.199->66.809, -85.390, -56.104%, 4\n",
      "152.199->77.118, -75.081, -49.331%, 5\n",
      "====== num_models = 3 ====================================\n",
      "228.298->82.603, -145.696, -63.818%, 1\n",
      "228.298->67.035, -161.263, -70.637%, 2\n",
      "228.298->79.899, -148.400, -65.003%, 3\n",
      "228.298->82.614, -145.685, -63.813%, 4\n",
      "228.298->77.641, -150.657, -65.991%, 5\n",
      "====== num_models = 4 ====================================\n",
      "304.398->96.848, -207.550, -68.184%, 1\n",
      "304.398->81.203, -223.195, -73.323%, 2\n",
      "304.398->93.796, -210.602, -69.187%, 3\n",
      "304.398->96.436, -207.961, -68.319%, 4\n",
      "304.398->98.927, -205.471, -67.501%, 5\n",
      "====== num_models = 5 ====================================\n",
      "380.497->110.147, -270.350, -71.052%, 1\n",
      "380.497->82.226, -298.271, -78.390%, 2\n",
      "380.497->104.564, -275.934, -72.519%, 3\n",
      "380.497->109.419, -271.079, -71.243%, 4\n",
      "380.497->99.115, -281.382, -73.951%, 5\n",
      "====== num_models = 6 ====================================\n",
      "456.597->119.752, -336.845, -73.773%, 1\n",
      "456.597->96.858, -359.739, -78.787%, 2\n",
      "456.597->124.674, -331.923, -72.695%, 3\n",
      "456.597->127.004, -329.593, -72.185%, 4\n",
      "456.597->119.051, -337.546, -73.926%, 5\n",
      "====== num_models = 7 ====================================\n",
      "532.696->150.704, -381.992, -71.709%, 1\n",
      "532.696->110.164, -422.532, -79.320%, 2\n",
      "532.696->136.649, -396.048, -74.348%, 3\n",
      "532.696->139.723, -392.974, -73.771%, 4\n",
      "532.696->132.748, -399.949, -75.080%, 5\n",
      "====== num_models = 8 ====================================\n",
      "608.796->169.718, -439.078, -72.122%, 1\n",
      "608.796->112.367, -496.429, -81.543%, 2\n",
      "608.796->148.626, -460.170, -75.587%, 3\n",
      "608.796->152.069, -456.727, -75.021%, 4\n",
      "608.796->136.853, -471.943, -77.521%, 5\n",
      "====== num_models = 9 ====================================\n",
      "684.895->177.256, -507.640, -74.119%, 1\n",
      "684.895->126.374, -558.522, -81.548%, 2\n",
      "684.895->159.153, -525.742, -76.762%, 3\n",
      "684.895->164.807, -520.089, -75.937%, 4\n",
      "684.895->154.694, -530.202, -77.414%, 5\n",
      "====== num_models = 10 ====================================\n",
      "760.995->181.325, -579.670, -76.173%, 1\n",
      "760.995->128.573, -632.422, -83.105%, 2\n",
      "760.995->171.339, -589.656, -77.485%, 3\n",
      "760.995->181.138, -579.857, -76.197%, 4\n",
      "760.995->157.892, -603.103, -79.252%, 5\n",
      "====== num_models = 11 ====================================\n",
      "837.094->212.224, -624.870, -74.647%, 1\n",
      "837.094->141.858, -695.237, -83.054%, 2\n",
      "837.094->192.420, -644.674, -77.013%, 3\n",
      "837.094->194.345, -642.750, -76.783%, 4\n",
      "837.094->176.956, -660.138, -78.861%, 5\n",
      "====== num_models = 12 ====================================\n",
      "913.194->217.066, -696.128, -76.230%, 1\n",
      "913.194->153.252, -759.942, -83.218%, 2\n",
      "913.194->205.320, -707.874, -77.516%, 3\n",
      "913.194->208.580, -704.614, -77.159%, 4\n",
      "913.194->192.439, -720.755, -78.927%, 5\n",
      "====== num_models = 13 ====================================\n",
      "989.293->222.217, -767.077, -77.538%, 1\n",
      "989.293->159.524, -829.770, -83.875%, 2\n",
      "989.293->215.226, -774.068, -78.244%, 3\n",
      "989.293->223.604, -765.690, -77.398%, 4\n",
      "989.293->196.581, -792.712, -80.129%, 5\n",
      "====== num_models = 14 ====================================\n",
      "1065.393->230.452, -834.941, -78.369%, 1\n",
      "1065.393->173.595, -891.798, -83.706%, 2\n",
      "1065.393->234.387, -831.006, -78.000%, 3\n",
      "1065.393->236.449, -828.944, -77.806%, 4\n",
      "1065.393->213.584, -851.808, -79.953%, 5\n",
      "====== num_models = 15 ====================================\n",
      "1141.492->240.181, -901.312, -78.959%, 1\n",
      "1141.492->181.867, -959.625, -84.068%, 2\n",
      "1141.492->244.108, -897.385, -78.615%, 3\n",
      "1141.492->251.773, -889.719, -77.943%, 4\n",
      "1141.492->216.420, -925.072, -81.041%, 5\n",
      "====== num_models = 16 ====================================\n",
      "1217.592->253.126, -964.466, -79.211%, 1\n",
      "1217.592->195.259, -1022.333, -83.963%, 2\n",
      "1217.592->254.808, -962.784, -79.073%, 3\n",
      "1217.592->266.724, -950.868, -78.094%, 4\n",
      "1217.592->235.123, -982.469, -80.690%, 5\n",
      "====== num_models = 17 ====================================\n",
      "1293.691->267.497, -1026.195, -79.323%, 1\n",
      "1293.691->204.793, -1088.898, -84.170%, 2\n",
      "1293.691->266.871, -1026.820, -79.371%, 3\n",
      "1293.691->278.595, -1015.096, -78.465%, 4\n",
      "1293.691->251.313, -1042.378, -80.574%, 5\n",
      "====== num_models = 18 ====================================\n",
      "1369.791->274.445, -1095.346, -79.964%, 1\n",
      "1369.791->216.817, -1152.974, -84.172%, 2\n",
      "1369.791->278.345, -1091.446, -79.680%, 3\n",
      "1369.791->293.966, -1075.825, -78.539%, 4\n",
      "1369.791->255.942, -1113.849, -81.315%, 5\n",
      "====== num_models = 19 ====================================\n",
      "1445.890->289.409, -1156.482, -79.984%, 1\n",
      "1445.890->227.927, -1217.964, -84.236%, 2\n",
      "1445.890->290.657, -1155.233, -79.898%, 3\n",
      "1445.890->307.435, -1138.456, -78.737%, 4\n",
      "1445.890->271.516, -1174.374, -81.222%, 5\n",
      "====== num_models = 20 ====================================\n",
      "1521.990->302.305, -1219.685, -80.138%, 1\n",
      "1521.990->236.824, -1285.166, -84.440%, 2\n",
      "1521.990->301.871, -1220.119, -80.166%, 3\n",
      "1521.990->322.318, -1199.672, -78.823%, 4\n",
      "1521.990->276.423, -1245.567, -81.838%, 5\n"
     ]
    }
   ],
   "source": [
    "# i = 0\n",
    "# greedy_partition = []\n",
    "\n",
    "bs = 8\n",
    "num_models = 3\n",
    "\n",
    "\n",
    "for num_models in range(2, 21):\n",
    "    print(f\"====== {num_models = } ====================================\")\n",
    "    for rank in range(1, 6):\n",
    "        new_subnet_bs = (bs,) * num_models\n",
    "\n",
    "        new_ranks = (rank,) * num_models\n",
    "        # print(f\"\\tNEW\\t {bs=} {rank=} x {num_models}\")\n",
    "        new_inout_shapes = [[bs, NUM_FEATURE, 32, 32] for bs in new_subnet_bs]\n",
    "        new_kernel = FusedLayer(\n",
    "            [conv2d] * len(new_subnet_bs),\n",
    "            new_inout_shapes,\n",
    "            new_inout_shapes,\n",
    "            new_ranks,\n",
    "        )\n",
    "        new_x = [torch.empty(shp, device=\"cuda\") for shp in new_inout_shapes]\n",
    "        new_time = (\n",
    "            Timer(\n",
    "                f\"new_kernel(new_x)\",\n",
    "                setup=\"from __main__ import new_kernel, new_x; import torch; torch.cuda.synchronize();\",\n",
    "            )\n",
    "            .timeit(100)\n",
    "            .mean\n",
    "            * 10e6\n",
    "        )\n",
    "        jit_kernel_info[(new_subnet_bs, new_ranks)] = new_time\n",
    "        old_time = (\n",
    "            min(jit_kernel_info[((bs,), (rank,))] for rank in range(1, 6)) * num_models\n",
    "        )\n",
    "        print(\n",
    "            f\"{old_time:.3f}->{new_time:.3f}, {new_time-old_time:.3f}, {100 * (new_time/old_time-1):.3f}%, {new_ranks[-1]}\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ada0f2bafc207a9420389a0d15036c00ed757384986ead74c3b832cdd2f7c4ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
