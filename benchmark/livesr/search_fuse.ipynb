{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.benchmark import Timer\n",
    "\n",
    "from brt.jit import make_jit_kernel\n",
    "\n",
    "from archs.fuse import TunedKernel, FusedLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "import more_itertools as mit\n",
    "from more_itertools import set_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[12]': 333.6390014737844,\n",
      " '[27]': 773.7475913017988,\n",
      " '[4]': 168.63897908478975,\n",
      " '[6]': 204.3970162048936,\n",
      " '[7]': 260.6593072414398,\n",
      " '[8]': 263.308291323483}\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(36, 36, 3, padding=1).eval().cuda()\n",
    "subnet_bs = sorted([6, 7, 12, 27, 8, 8, 8, 12, 12, 4]) # [4, 6, 7, 8, 8, 8, 12, 12, 12, 27]\n",
    "\n",
    "jit_kernel_info = {}\n",
    "for bs in set(subnet_bs):\n",
    "    inout_shape = [bs, 36, 32, 32]\n",
    "    x = torch.empty(inout_shape, device=\"cuda\")\n",
    "    kernel = TunedKernel(conv2d, inout_shape, inout_shape)\n",
    "    time = Timer(\n",
    "        f\"kernel(x)\",\n",
    "        setup=\"from __main__ import kernel, x; import torch; torch.cuda.synchronize();\",\n",
    "    ).timeit(100).mean * 10e6\n",
    "    jit_kernel_info[str([bs])] = time\n",
    "\n",
    "pprint(jit_kernel_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW\t [4]\n",
      "      \t 373.036->349.433, -23.603, -6.327%\n",
      "APPEND\t [4, 6]\n",
      "      \t 610.092->841.940, 231.848, 38.002%\n",
      "FINALLY\t [4, 6]\n",
      "NEW\t [7]\n",
      "      \t 523.968->730.111, 206.143, 39.343%\n",
      "FINALLY\t [7]\n",
      "NEW\t [8]\n",
      "      \t 526.617->487.886, -38.731, -7.355%\n",
      "APPEND\t [8, 8]\n",
      "      \t 751.194->670.037, -81.157, -10.804%\n",
      "APPEND\t [8, 8, 8]\n",
      "      \t 1003.676->996.740, -6.936, -0.691%\n",
      "APPEND\t [8, 8, 8, 12]\n",
      "      \t 1330.379->1243.815, -86.564, -6.507%\n",
      "APPEND\t [8, 8, 8, 12, 12]\n",
      "      \t 1577.454->1521.812, -55.642, -3.527%\n",
      "APPEND\t [8, 8, 8, 12, 12, 12]\n",
      "      \t 2295.560->2585.217, 289.658, 12.618%\n",
      "FINALLY\t [8, 8, 8, 12, 12, 12]\n",
      "NEW\t [27]\n",
      "FINALLY\t [27]\n",
      "[[4, 6], [7], [8, 8, 8, 12, 12, 12], [27]]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "greedy_partition = []\n",
    "while i < len(subnet_bs):\n",
    "    cur_subnet_bs = [subnet_bs[i]]\n",
    "    print(f\"NEW\\t {cur_subnet_bs}\")\n",
    "    i = i + 1\n",
    "\n",
    "    while i < len(subnet_bs):\n",
    "        cur_time = jit_kernel_info[str(cur_subnet_bs)]\n",
    "        new_subnet_bs = cur_subnet_bs + [subnet_bs[i]]\n",
    "        new_inout_shapes = [[bs, 36, 32, 32] for bs in new_subnet_bs]\n",
    "        new_x = [torch.empty(shp, device=\"cuda\") for shp in new_inout_shapes]\n",
    "        new_kernel = FusedLayer([conv2d] * len(new_subnet_bs), new_inout_shapes, new_inout_shapes)\n",
    "        new_time = Timer(\n",
    "            f\"new_kernel(new_x)\",\n",
    "            setup=\"from __main__ import new_kernel, new_x; import torch; torch.cuda.synchronize();\",\n",
    "        ).timeit(100).mean * 10e6\n",
    "        jit_kernel_info[str(new_subnet_bs)] = new_time\n",
    "        old_time = jit_kernel_info[str(cur_subnet_bs)] + jit_kernel_info[str([subnet_bs[i]])]\n",
    "        print(f\"      \\t {old_time:.3f}->{new_time:.3f}, {new_time-old_time:.3f}, {100 * (new_time/old_time-1):.3f}%\")\n",
    "        if new_time < old_time:\n",
    "            cur_subnet_bs = new_subnet_bs\n",
    "            print(f\"APPEND\\t {cur_subnet_bs}\")\n",
    "        else:\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "    print(f\"FINALLY\\t {cur_subnet_bs}\")\n",
    "    greedy_partition.append(cur_subnet_bs)\n",
    "\n",
    "print(greedy_partition)\n",
    "# [[4, 6], [7], [8, 8, 8, 12, 12, 12], [27]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198.2847722247243\n",
      "2905.6517872959375\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([jit_kernel_info[str([bs])] for bs in subnet_bs])}\")\n",
    "print(f\"{sum([jit_kernel_info[str(bs)] for bs in greedy_partition])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ada0f2bafc207a9420389a0d15036c00ed757384986ead74c3b832cdd2f7c4ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
